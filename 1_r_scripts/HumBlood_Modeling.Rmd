---
title: "Comparative Hummingbird Blood: Modeling"
author: "Jessie Williamson"
date: "11/09/2020; Last Updated: 3/2/21"
output:
  md_document:
    variant: markdown_github

---

This script includes: Reading in pre-processed data from "HumBlood_DataWrangling.Rmd", standardizing predictors, making data subsets that match subsetted phylogenies (so there are no NAs in any dataset for modeling), and then running, checking, plotting sets of Bayesian phylogenetic mixed models. 

Instructions for installing RStan for brms models: https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started
Instructions for configuring toolchain for brms models (Mac): https://github.com/stan-dev/rstan/wiki/Configuring-C---Toolchain-for-Mac

#######


```{R, echo=FALSE}
# GLOBAL R chunk options here (hide message w/ echo=FALSE)
knitr::opts_chunk$set(comment = NA, message = FALSE, warning = FALSE, width = 100)
knitr::opts_chunk$set(fig.align = "center", fig.height = 4, fig.width = 6)
knitr::opts_chunk$set(cache = TRUE, autodep=TRUE)
```


# Load packages
```{R}
library(reshape)
library(reshape2)
library(plyr)
library(dplyr)
library(car)
library(GGally)
library(Hmisc)
library(gridExtra)
library(stats)
library(gplots)
library(ggplot2)
library(stats4) # Forces knitr to work when it's being wonky
library(PMCMR) #Allows Kruskal-Wallis post-hocs
library(effects)
library(gridExtra)
library(lattice)
# library(survival)
# library(fmsb)
library(faraway)
library(tidyverse)
library(patchwork) 
library(viridis)
library(rcompanion) # for Tukey's Ladder of Powers Transformation
library(purrr)
library(tidyr)
library(cowplot)
library(gganimate)
library(job) # Run slow brms models as jobs to free up console

# Bayesian modeling packages 
library(MCMCglmm)
library(bayesplot)
library(rstan)
library(Rcpp) # required for brms
library(brms) # updated to 2.15.0 on 3/29/21
library(bayesplot) # appears to be required for bayesplot::pp_check?
library(ggdist)
library(tidybayes)
library(performance)

# To run each time you load rstan
options(mc.cores = parallel::detectCores()) # for core setup 
rstan_options(auto_write = TRUE) # auto save  bare verion of compiled Stan program to HD
# rstan output should always end in a blank line w/ no characters or spaces  

# Phylo packages 
library(phytools)
# library(ape)

# Frequentist modeling packages
# library(nlme)
# library(lme4)
# library(AICcmodavg)
# library(MuMIn)
# library(glmulti)
# library(lsmeans)
# library(rsq) # get r-squared values from GLM
# library(r2glmm) # for R^2 values from lmer() and glmer()
# library(multcompView) # related to multiple comparisons?
# library(jtools) # interaction plots 
# library(interactions) # interaction plots 
# library(broom)
# library(stargazer) # model output tables
# library(ggeffects) # for estimating model predictions from mixed effects models
```


---

# Clear workspace and set WD
```{R}
rm(list=ls(all=TRUE)) # clear workspace 
setwd("/Users/Jessie/Dropbox (MSBbirds)/Rdirectory/ComparativeHummingbirdBlood")
```


```{R}
# Load functions 
source("/Users/Jessie/Dropbox (MSBbirds)/Rdirectory/ComparativeHummingbirdBlood/1_r_scripts/ada_functions.R") 
  # Erik's ADA functions for clean & collated lm diag plots
source("/Users/Jessie/Dropbox (MSBbirds)/Rdirectory/ComparativeHummingbirdBlood/1_r_scripts/Rfunctions.R") # Nora's functions

# Final hummingbird blood dataset
# Don't need to load if already loaded from another script 
# Unlike tree file, you want all categorical variables to be factors for modeling
# final <- read.csv("AllHummingbirdBlood_Wrangled_withBioClim_andPCA_NoHbGenotypes_08-26-20.csv", stringsAsFactors = TRUE)
final <- read.csv("AllHummingbirdBlood_Wrangled_withBioClim_andPCA_03-01-21.csv", stringsAsFactors = TRUE)
final <- final[ , !(colnames(final) %in% c("X"))] # drop weird X column 1 if reading in from read.csv
names(final)[names(final) == "b13b83.genotype"] <- "genotype" # Make this column header simpler 
final$rowID <- 1:nrow(final) # Re-add row ID; this somehow got a bit messed up

# Phylogeny pruned from McGuire and adjusted (see script HumBlood_Phylogeny.Rmd)
tree <- read.tree("McGuirePruned_AllHummingbirdComparativeTree_FINAL.tre") # a list 
tree$tip.label # Check 77 tips

# Write out final tree file as pdf for figure-making
# In order to write out .pdf tree file: 1) Initiate pdf (or jpeg, etc) file; 2) Plot tree w/ all graphics; 3) dev.off to save
pdf("McGuirePruned_AllHummingbirdComparativeTree_FINAL.pdf", width=5, height=6) 
plotTree(tree, ftype="i") # Check this pre-final tree w/ adjusted branch lengths 
dev.off()

# Read in sub trees 
tree.hb <- read.tree("McGuirePruned_AllHummingbirdComparative_Tree.hb_FINAL.tre")  
tree.hct <- read.tree("McGuirePruned_AllHummingbirdComparativeTree.hct_FINAL.tre")  
tree.trbc <- read.tree("McGuirePruned_AllHummingbirdComparativeTree.trbc_FINAL.tre") 
tree.mcv <- read.tree("McGuirePruned_AllHummingbirdComparativeTree.mcv_FINAL.tre") 
tree.mch <- read.tree("McGuirePruned_AllHummingbirdComparativeTree.mch_FINAL.tre") 
tree.mchc <- read.tree("McGuirePruned_AllHummingbirdComparativeTree.mchc_FINAL.tre")

# Check all data structures
str(final)
# str(final.hb)
# str(final.hct)
# str(final.mcv)
# str(final.trbc)
# str(final.mch)
# str(final.mchc)
```


# PREP DATA FOR MODELING
Further clean for modeling: transform variables, calculate intraspecific variation, generate response variable-specific subsets conduct tests of phylogenetic signal.  

# Coerce structure and assess normality of variables; transform as necessary 
```{r}
# Since we confirmed above that the only missing data is due to blood characteristics at this point, 
# We can be sure that na.omit is only removing missing blood values for each response variable. 

# Coerce structure here so that subsets retain this same structure 
str(final)
final$species <- as.factor(final$species)
final$sex <- as.factor(final$sex)
final$age <- as.factor(final$age)
final$month <- as.factor(final$month)
final$locality <- as.factor(final$locality)
final$department <- as.factor(final$department)
final$Clade <- as.factor(final$Clade)
#final$range_class <- as.factor(final$range_class)
#final$po2_class <- as.factor(final$po2_class)
```


# Calculate intraspecific variation (within-species metrics)
```{R}
# Do this before standardizing so calculations are done on raw values and standardizing happens AFTERWARDS
# (Otherwise you'll be using standardized values to calculate raw metrics, if that makes sense)
# Also because log-transforming doesn't alter some values based on others; standardizing data does 

# Calculate standardized within-species variability in predictors (NOT RESPONSE)
final$spec.mean.elev <- with(final, sapply(split(elev, species), mean)[species]) # species means for of predictors
#final$spec.mean.elev.pos <- with(final, sapply(split(elev_position, species), mean)[species])
final$spec.mean.temp <- with(final, sapply(split(tempPC1, species), mean)[species])
final$spec.mean.precip <- with(final, sapply(split(precipPC1, species), mean)[species])
final$spec.mean.mass <- with(final, sapply(split(mass, species), mean)[species]) # RAW MASS, NOT LOG MASS (log was wonky)

# MORE MASS STUFF (a little more complicated): 
# Now, since we know that males and females have substially different body masses *and* blood characteristics are expected
# to differ by sex, we want to calculate intraspecific variation for females w/ female mean mass, intaspecific variation for 
# males w/ male mean mass, and we'll use species mean mass for the n=6 unknown sexes. 
# Nice n clunky n simple way of doing this: split data frame by sex, calculate mean masses per sex, and rbind back together 

species.mass.summary <- final %>% group_by(species, sex) %>% # Summary of species masses by sex 
                              dplyr::summarize(mean_mass = mean(mass, na.rm = TRUE), count =n())
X <- split(final, final$sex) # split data frame by sex 
females <- as.data.frame(X[[1]]) # Make data frames from list elements 
males <- as.data.frame(X[[2]])
unknowns <- as.data.frame(X[[3]])

females$spec.mean.mass <- with(females, sapply(split(mass, species), mean)[species])
males$spec.mean.mass <- with(males, sapply(split(mass, species), mean)[species])
# Calculate mean masses for each males and females
# Keep column header name the same for merging (& note that you'll write over original "spec.mean.mass" for each of these subsets)
# These values should match values in "species.mass.summary"
final <- rbind(females, males, unknowns) # Recombine subsets; write over same data frame name

# NOW, Calculate individual differences from species mean value (aka intraspecific variation, or 'intravar'); within-sp diffs
final$intravar.mass <- final$mass - final$spec.mean.mass
final$intravar.temp <- final$tempPC1 - final$spec.mean.temp
final$intravar.precip <- final$precipPC1 - final$spec.mean.precip

# Out of curiosity, how broad is intraspecific variation in mass across the spcies in our dataset? 
# intravar.mass.summary <- final %>% group_by(species) %>% dplyr::summarize(mean_intravar_mass = mean(intravar.mass, na.rm = TRUE), count =n())
```


# Check normality and distributions; transform non-normal variables as necessary 
```{r}
# Predictor dataset - take a look at distributions
p <- ggpairs(subset(final, select = c(hb, hct, trbc, mcv, mch, mchc, mass, wl, elev, elev_position, tempPC1, precipPC1))) 
print(p)

# FIRST: RESPONSE VARIABLES 
# Hb, Hct, and TRBC look fantastic - no need to transform 

# MCV: quick comparison of untransformed and transformed MCV suggests that MCV fits MUCH BETTER when log-transformed 
final$mcv.log <- log10(final$mcv) # Distribution and tails look fantastic after log transformation 
plotNormalHistogram(final$mcv) 
plotNormalHistogram(final$mcv.log) 
qqPlot(final$mcv) 
qqPlot(final$mcv.log) 

# MCH: quick comparison of untransformed and transformed MCH suggests that MCH fits MUCH BETTER when log-transformed 
final$mch.log <- log10(final$mch) # Fantastic after log-transform 
plotNormalHistogram(final$mch) 
plotNormalHistogram(final$mch.log) 
qqPlot(final$mch) 
qqPlot(final$mch.log) 

# MCHC: Distribution has somewhat heavy tails. Log transforming shifts "fit" around tails and doesn't advance goal of normality. 
# I think this would be better adjusted with priors to account for heavy/long tails. 


# SECOND: PREDICTORS 

# MASS: Better after log transformation but still really off at right tail
final$mass.log <- log10(final$mass) # Helped a bit, but still pretty off at tails, definitely not normal
hist(final$mass.log) 
qqPlot(final$mass.log) 

# TEMPPC1: log-transforming doesn't help! Heavy tails, transforming (even w/ Tukey's ladder of powers = not good)
# full$wl.tuk <- transformTukey(full$wl, plotit=TRUE)
# test$tempPC1.tuk <- transformTukey(test$tempPC1, plotit=TRUE) # Right hand tail a bit iffy but w/ log transformation it's largely w/in confidence interval
# plotNormalHistogram(test$tempPC1) 
# plotNormalHistogram(test$tempPC1.tuk) 
# qqPlot(test$tempPC1) 
# qqPlot(test$tempPC1.tuk) 

# TEMPPC2: log and tukey's don't help, produce weird NA and NaN values = no good 
# test$precipPC1.tuk <- transformTukey(test$precipPC1, plotit=TRUE) # Right hand tail a bit iffy but w/ log transformation it's largely w/in confidence interval
# plotNormalHistogram(test$precipPC1) 
# plotNormalHistogram(test$precipPC1.tuk) 
# qqPlot(test$precipPC1) 
# qqPlot(test$precipPC1.tuk) 


# WING LOADING: original wing loading distribution is delightfully normal, but when each of these means are "spread" across 
# our big dataset so that they can be used for modeling, the distribution becomes wonky. 
# It would be best to get original wing loading data from Chris and to be able to use these individual-level vs. mean values.
 
# Raw data checks from 'wload': Data normally distributed, look good in original data (histogram, qqPlot, shapiro test checks):
# plotNormalHistogram(wload$wl) 
# qqPlot(wload$wl)
# shapiro.test(final$hb) # passes normality test, p > 0.05 
# 
# # but...when we "spread" mean values across individual dataset, bad stuff happens to normality: 
# plotNormalHistogram(full$wl)  
# qqPlot(final$wl) # weird data spread caused by "smearing" species means across individual-level data 
# shapiro.test(full$wl) # fails normality, p < 0.05

# I played around w/ log transformations for wl; untransformed data fit much better 
# final$wl.log <- log10(final$wl)
# hist(final$wl)
# hist(final$wl.log)
# qqPlot(final$wl)
# qqPlot(final$wl.log)

# So, ideally need to transform wing data in 'final', BUT: 
# Cube, log, and square root transformations look about the same, fit poorly, and aren't normal; ditch these 
# Tukey's Ladder of Powers transformation is *marginally* better, but hardly 
# Tukey's Ladder of Powers: performs iterative Shapiro–Wilk tests, finds lambda value that maximizes W statistic from tests.  
# AKA, it finds power transformation that makes data fit normal distribution as closely as possible. 
# full$wl.tuk <- transformTukey(full$wl, plotit=TRUE)
# plotNormalHistogram(full$wl.tuk) 
# qqPlot(full$wl.tuk)
# shapiro.test(full$wl.tuk) # still fails Shapiro-Wilk, but bigger indicator is poor qqPlot fit (tails look terrible)

# Ideally, get individual-level wing loading data and substitute with species means were necessary 

#####

# Predictor dataset after transformations - take a look at distributions
# p <- ggpairs(subset(final, select = c(hb, hct, trbc, mcv.log, mch.log, mchc, mass.log, elev, elev_position, tempPC1, precipPC1)))
# print(p)
```

More on Tukey's Ladder of Powers transformation here: https://rcompanion.org/handbook/I_12.html#:~:text=For%20left%2Dskewed%20data%E2%80%94tail,log%20(constant%20%E2%80%93%20x).

# Standardize predictors 
```{R}
# Standardize continuous PREDICTOR variables to mean of 0 and standard deviation of 1:
# Remember: responses don't get standardized 
# NOTE: Standardizing is really only necessary because of elev as predictor, which throws off scale a ton 
# final <- get.complete.cases(final) # Returns only 100% complete rows (aka drops any row with an NA) 
final$elev.z <- standardize(final$elev)
final$temp.z <- standardize(final$tempPC1)
final$precip.z <- standardize(final$precipPC1)
final$mass.z <- standardize(final$mass.log) # NOTE: THIS IS LOG MASS STANDARDIZED, NOT RAW MASS
final$elev.pos.z <- standardize(final$elev_position)
final$wl.z <- standardize(final$wl)

# Standardize species means
final$spec.mean.elev.z <- standardize(final$spec.mean.elev)
final$spec.mean.temp.z <- standardize(final$spec.mean.temp)
final$spec.mean.precip.z <- standardize(final$spec.mean.precip)
final$spec.mean.mass.z <- standardize(final$spec.mean.mass)

# Now standardize intraspecific variation 
final$intravar.mass.z <- standardize(final$intravar.mass)
final$intravar.temp.z <- standardize(final$intravar.temp)
final$intravar.precip.z <- standardize(final$intravar.precip)

# Predictor after transformations and standardization - take a look at distributions
# p <- ggpairs(subset(final, select = c(mass.z, wl.z, elev.z, elev.pos.z, temp.z, precip.z, intravar.mass.z, intravar.temp.z, intravar.precip.z)))
# print(p)
```


# Make data subsets that would be dropped from big dataset with na.omit 
We're generating subsets now to be able to retain the max amount of data for each 
i.e. if we just used na.omit to be able to run models smoothly, we'd lose hundreds of Hb measurements that didn't also have MCV values, for example. 
```{R}
# NOTE: If we decide to move forward with wing loading data, include wl data in each of these subsets.

# Hb subset - 988 observations
final.hb <- subset(final, select=c(species, rowID, nk, sex, age, month, year, locality, elev, department, lat, lon, mass, mass.log, hb, Clade, elev_position, tempPC1, precipPC1, mass.z, elev.z, elev.pos.z, temp.z, precip.z, b13, b83, genotype, intravar.mass, intravar.temp, intravar.precip, intravar.mass.z, intravar.temp.z, intravar.precip.z)) 
final.hb <- na.omit(final.hb)
str(final.hb) # looks good, nothing to coerce 

# Hct subset - 1086 observations
final.hct <- subset(final, select=c(species, rowID, nk, sex, age, month, year, locality, elev, department, lat, lon, mass, mass.log, hct, Clade, elev_position, tempPC1, precipPC1, mass.z, elev.z, elev.pos.z, temp.z, precip.z, b13, b83, genotype, intravar.mass, intravar.temp, intravar.precip, intravar.mass.z, intravar.temp.z, intravar.precip.z)) 
final.hct <- na.omit(final.hct)
str(final.hct) # looks good, nothing to coerce 

# trbc subset - 748 observations
final.trbc <- subset(final, select=c(species, rowID, nk, sex, age, month, year, locality, elev, department, lat, lon, mass, mass.log, trbc, Clade, elev_position, tempPC1, precipPC1, mass.z, elev.z, elev.pos.z, temp.z, precip.z, b13, b83, genotype,intravar.mass, intravar.temp, intravar.precip, intravar.mass.z, intravar.temp.z, intravar.precip.z)) 
final.trbc <- na.omit(final.trbc)
str(final.trbc) # looks good, nothing to coerce

# mcv subset - 732 observations
final.mcv <- subset(final, select=c(species, rowID, nk, sex, age, month, year, locality, elev, department, lat, lon, mass, mass.log, mcv, Clade, elev_position, tempPC1, precipPC1, mass.z, elev.z, elev.pos.z, temp.z, precip.z, b13, b83, genotype, intravar.mass, intravar.temp, intravar.precip, intravar.mass.z, intravar.temp.z, intravar.precip.z, mcv.log, spec.mean.elev.z, spec.mean.temp.z, spec.mean.precip.z, spec.mean.mass.z)) 
final.mcv <- na.omit(final.mcv)
str(final.mcv) # looks good, nothing to coerce 

# mch subset - 703 observations
final.mch <- subset(final, select=c(species, rowID, nk, sex, age, month, year, locality, elev, department, lat, lon, mass, mass.log, mch, Clade, elev_position, tempPC1, precipPC1, mass.z, elev.z, elev.pos.z, temp.z, precip.z, b13, b83, genotype, intravar.mass, intravar.temp, intravar.precip, intravar.mass.z, intravar.temp.z, intravar.precip.z, mch.log)) 
final.mch <- na.omit(final.mch)
str(final.mch) # looks good, nothing to coerce 

# mchc subset - 924 observations
final.mchc <- subset(final, select=c(species, rowID, nk, sex, age, month, year, locality, elev, department, lat, lon, mass, mass.log, mchc, Clade, elev_position, tempPC1, precipPC1, mass.z, elev.z, elev.pos.z, temp.z, precip.z, b13, b83, genotype, intravar.mass, intravar.temp, intravar.precip, intravar.mass.z, intravar.temp.z, intravar.precip.z)) 
final.mchc <- na.omit(final.mchc)
str(final.mchc) # looks good, nothing to coerce 

# Write out all final data subsets: 
# write.csv(final.hb, "HumBlood_final.hb.csv")
# write.csv(final.hct, "HumBlood_final.hct.csv")
# write.csv(final.trbc, "HumBlood_final.trbc.csv")
# write.csv(final.mcv, "HumBlood_final.mcv.csv")
# write.csv(final.mch, "HumBlood_final.mch.csv")
# write.csv(final.mchc, "HumBlood_final.mchc.csv")
```


# Check for matches with phylogeny tips and datasets  
```{r}
# Need to insert underscores into all species names to match phylogenies 
final$species <- gsub(" ", "_", final$species)
final.hb$species <- gsub(" ", "_", final.hb$species)
final.hct$species <- gsub(" ", "_", final.hct$species)
final.mch$species <- gsub(" ", "_", final.mch$species)
final.mchc$species <- gsub(" ", "_", final.mchc$species)
final.mcv$species <- gsub(" ", "_", final.mcv$species)
final.trbc$species <- gsub(" ", "_", final.trbc$species)

# Are the phylogeny tip labels in the data and vice-versa?
# FULL DATASET 
tree$tip.label %in% final$species # yes
sum(tree$tip.label %in% final$species) # sum = 77 
summary(tree$tip.label %in% final$species) # yes 

# HB DATA
tree.hb$tip.label %in% final.hb$species # yes
sum(tree.hb$tip.label %in% final.hb$species) # sum = 74
summary(tree.hb$tip.label %in% final.hb$species) # yes 

# HCT DATA:
tree.hct$tip.label %in% final.hct$species # yes
sum(tree.hct$tip.label %in% final.hct$species) # sum = 76
summary(tree.hct$tip.label %in% final.hct$species) # yes 

# MCH DATA 
tree.mch$tip.label %in% final.mch$species # yes
sum(tree.mch$tip.label %in% final.mch$species) # sum = 69
summary(tree.mch$tip.label %in% final.mch$species) # yes 

# MCHC DATA 
tree.mchc$tip.label %in% final.mchc$species # yes
sum(tree.mchc$tip.label %in% final.mchc$species) # sum = 73
summary(tree.mchc$tip.label %in% final.mchc$species) # yes 

# MCV DATA 
tree.mcv$tip.label %in% final.mcv$species # yes
sum(tree.mcv$tip.label %in% final.mcv$species) # sum = 72
summary(tree.mcv$tip.label %in% final.mcv$species) # yes 

# TRBC DATA 
tree.trbc$tip.label %in% final.trbc$species # yes
sum(tree.trbc$tip.label %in% final.trbc$species) # sum = 72
summary(tree.trbc$tip.label %in% final.trbc$species) # yes 

# Good: all datasets and tree tips match 
```



# Check contMaps for trait and sampling outliers (Mean values from contMaps necessary for phylo tests below)
Before moving on with pre-modeling verification and modeling itself, work up continuous trait maps for each of the 6 blood parameters to take a look at phylo signal and spread of values. Based on preliminary modeling efforts, we expect low phylogenetic signal (i.e. similar branch colors) aross the board. But, in a few cases, extreme values may be driven by low sampling (i.e. n=1 or n<3). We have decided to remove the phylogenetic component to models because signal is nonexistant, but another approach might be to carefully consider and possibly exclude "sampling outlier" cases. 
```{r}
# NOTE: See Lisa's tutorial on this, called amphibian_PhyloMethods_Mar2020.R" - more helpful than Phytools tutorials! 
# IMPORTANT: don't forget to attach species names to the trait! 
# AND, don't do this with rownames(), which changes data format. Do this as Lisa has done w/ 'names()'. 
# You want the format to read 'Named num'; class = numeric; type = double 

# HB 
# Subset by species and mean(hb) to make trait matrix for Phytools contMap (annotations here, streamlined below)
hb.contmap <- final.hb %>% group_by(species) %>% summarise(hb = mean(hb)) # HB 
just.hb <- hb.contmap$hb # Take mean hb values only 
names(just.hb) <- hb.contmap$species # Add species names from the hb.contmap file (to match w/ Hb); don't use rownames()! 
class(just.hb); typeof(just.hb) #; View(just.hb) # Check data format and structure 

# Create hemoglobin continuous trait phylo object 
hb.cont.tree <- contMap(tree.hb, just.hb, plot=TRUE, outline=FALSE) 
# hb.cont.tree <- setMap(hb.cont.tree, colors=c("#280a52","#e9612c","#f7d03d")) # Set colors: purple, green, yellow
#n <- length(hb.cont.tree$cols); n # Find length of colors in contmap 

# Plot map and save to pdf w/ proper aesthetics 
pdf(file="hemoglobin.contmap.pdf", width=6, height=6)
#hb.cont.tree$cols[1:n] <- viridis(n) # Manually set color scale to viridis 
plot.contMap(hb.cont.tree, just.hb, res=200, fsize=0.4, lwd=2, leg.txt="Mean [Hb]", outline=FALSE) # Manually plot using phytools
#par(mar=c(5.1, 4.1, 0, 2.1)) ## reset margins to default
# Use outline=FALSE to remove black outlines from branches 
#title("[Hb]", xpd=TRUE, ) #Add a title manually 
#plot(hb.cont.tree, lwd=4, fsize=0.5) # setting xlim changes actual plot dimensions, NOT trait value scale 
dev.off()

# Quick test with medians - Chauncey pointed out that medians might be more appropriate and less skewed towards outliers. 
# This quick test reveals essentially no difference between mean and median values; convinces me that there really is no signal.
# (though this doesn't eliminate 'sampling outlier' issue, as values for n=1 will be same regardless of mean or median)
# hb.contmap.median <- final.hb %>% group_by(species) %>% summarise(hb = median(hb)) # HB 
# just.hb.median <- hb.contmap.median$hb # Take mean hb values only 
# names(just.hb.median) <- hb.contmap.median$species # Add species names from the hb.contmap file (to match w/ Hb); don't use rownames()! 
# View(just.hb.median); class(just.hb.median); typeof(just.hb.median) # Check data format and structure
# hb.cont.tree.median <- contMap(tree.hb, just.hb.median, plot=TRUE) # Create hemoglobin continuous trait phylo object 

###

# HCT 
hct.contmap <- final.hct %>% group_by(species) %>% summarise(hct = mean(hct))  
just.hct <- hct.contmap$hct
names(just.hct) <- hct.contmap$species 
class(just.hct); typeof(just.hct) #; View(just.hct)

# Make contmap object
hct.cont.tree <- contMap(tree.hct, just.hct, plot=TRUE, outline=FALSE) 

# Plot map and save to pdf w/ proper aesthetics 
pdf(file="hematocrit.contmap.pdf", width=6, height=6) # Write plot to pdf 
#hct.cont.tree$cols[1:n] <- viridis(n) # Manually set color scale to viridis 
plot.contMap(hct.cont.tree, just.hct, res=200, fsize=0.4, lwd=2, leg.txt="Mean Hct", outline=FALSE) # Manually plot using phytools
dev.off()

###

# TRBC 
trbc.contmap <- final.trbc %>% group_by(species) %>% summarise(trbc = mean(trbc))  
just.trbc <- trbc.contmap$trbc
names(just.trbc) <- trbc.contmap$species 
class(just.trbc); typeof(just.trbc) #; View(just.trbc) 

# Make contmap object
trbc.cont.tree <- contMap(tree.trbc, just.trbc, plot=TRUE, outline=FALSE) 

# Plot map and save to pdf w/ proper aesthetics 
pdf(file="trbc.contmap.pdf", width=6, height=6) # Write plot to pdf 
#trbc.cont.tree$cols[1:n] <- viridis(n) # Manually set color scale to viridis 
plot.contMap(trbc.cont.tree, just.trbc, res=200, fsize=0.4, lwd=2, leg.txt="Mean TRBC", outline=FALSE) # Manually plot using phytools
dev.off()

###

# MCV
mcv.contmap <- final.mcv %>% group_by(species) %>% summarise(mcv = mean(mcv))  
just.mcv <- mcv.contmap$mcv
names(just.mcv) <- mcv.contmap$species 
class(just.mcv); typeof(just.mcv) #; View(just.mcv)

# Make contmap object
mcv.cont.tree <- contMap(tree.mcv, just.mcv, plot=TRUE, outline=FALSE) 

# Plot map and save to pdf w/ proper aesthetics 
pdf(file="mcv.contmap.pdf", width=6, height=6) # Write plot to pdf 
#trbc.cont.tree$cols[1:n] <- viridis(n) # Manually set color scale to viridis 
plot.contMap(mcv.cont.tree, just.mcv, res=200, fsize=0.4, lwd=2, leg.txt="Mean MCV", outline=FALSE) # Manually plot using phytools
dev.off()

###

# MCH
mch.contmap <- final.mch %>% group_by(species) %>% summarise(mch = mean(mch))  
just.mch <- mch.contmap$mch
names(just.mch) <- mch.contmap$species 
class(just.mch); typeof(just.mch) #; View(just.mch)

# Make contmap object
mch.cont.tree <- contMap(tree.mch, just.mch, plot=TRUE, outline=FALSE)

# Plot map and save to pdf w/ proper aesthetics 
pdf(file="mch.contmap.pdf", width=6, height=6) # Write plot to pdf 
#trbc.cont.tree$cols[1:n] <- viridis(n) # Manually set color scale to viridis 
plot.contMap(mch.cont.tree, just.mch, res=200, fsize=0.4, lwd=2, leg.txt="Mean MCH", outline=FALSE) # Manually plot using phytools
dev.off()

###

# MCHC
mchc.contmap <- final.mchc %>% group_by(species) %>% summarise(mchc = mean(mchc))  
just.mchc <- mchc.contmap$mchc
names(just.mchc) <- mchc.contmap$species 
class(just.mchc); typeof(just.mchc) #; View(just.mchc)

# Make contmap object
mchc.cont.tree <- contMap(tree.mchc, just.mchc, plot=TRUE, outline=FALSE) 

# Plot map and save to pdf w/ proper aesthetics 
pdf(file="mchc.contmap.pdf", width=6, height=6) # Write plot to pdf 
#trbc.cont.tree$cols[1:n] <- viridis(n) # Manually set color scale to viridis 
plot.contMap(mchc.cont.tree, just.mchc, res=200, fsize=0.4, lwd=2, leg.txt="Mean MCHC", outline=FALSE) # Manually plot using phytools
dev.off()

# length value in legend = how many millions of years the legend bar represents (or whatever units are on tree edge lengths)
# Lamely, moosh all these together into an Illustrator figure to make Figure S1
```

Helpful continuous trait mapping tutorials: 
Phytoosl contMap() tutorial: http://www.phytools.org/***SanJuan2016/ex/15/Plotting-methods.html

Info on what trait value axis means, how to change colors of branches, and how to change "trait value" header in legend axis title: http://blog.phytools.org/2015/06/customizing-your-contmap-style.html

This is a good one for plotting multiple phylogenies: https://qcbs.ca/wp-content/uploads/2018/03/phylo_plot_02_03_2018.html

Changing color ramp in contmap: http://blog.phytools.org/2014/05/changing-color-ramp-in-contmap-or.html


# Tests of phylogenetic signal 
Although preliminary modeling results and contmaps show low phylogenetic signal, we conduct formal tests of phylogenetic signal here. Phylo signal will tell us whether close relatives are more similar than random pairs of species. 
```{r}
# Compute two metrics of phylogenetic signal: Blomberg's K and Pagel's lamda 
# Pagel's lambda: 0 = no phylo singal in the trait and 1 = phylo signal in the trait
# Blomberg's K: computed w/ p-val by comparing real data to null distribution obtained by random permuations. 
    # Values of K range from 0 to inf; K=1 = Brownian motion evol; k>1 = spp more similar than expected under random drift; 
    # k<1 = spp less similar than expected under random drift. The larger the K, the stronger the phylo signal. 
    # Generally, only K-values with significant p-vals indicate phylo signal

# For comparison with our data, let's quickly simulate data with no phylogenetic signal
# Note that this will change a bit when you run it because it's based on randomized #s
set.seed(12345)
x <- rnorm(100); names(x) <- tree$tip.label
phylosig(tree, x, test=TRUE) # K = 0.619, p = 0.622 = no signal 
phylosig(tree, x, method="lambda",test=TRUE) # lamda = < 0, p > 1 = no signal

# Compute Blomberg's K for 6 blood traits
# x must be a vector of a continuously distributed trait; I'll use vectors of mean values I created for contmaps (i.e. 'just.hb')
# w/ phylosig(), default is method="K" and nsim=1000

# Compute K and conduct a test of the null hypothesis of no phylogenetic signal
set.seed(1568)
phylosig(tree=tree.hb, x=just.hb, method="K", test=TRUE) # K=0.142, p=0.824
phylosig(tree=tree.hct, x=just.hct, method="K", test=TRUE) # K=0.172, p=0.732
phylosig(tree=tree.trbc, x=just.trbc, method="K", test=TRUE) # K=0.156, p=0.799
phylosig(tree=tree.mcv, x=just.mcv, method="K", test=TRUE) # K=0.213, p=0.56
phylosig(tree=tree.mch, x=just.mch, method="K", test=TRUE) # K=0.265, p=0.379
phylosig(tree=tree.mchc, x=just.mchc, method="K", test=TRUE) # K=0.209, p=0.604 

# Compute Pagel's lambda using maximum likelihood
phylosig(tree=tree.hb, x=just.hb, method="lambda", test=TRUE) # lambda=<0, p=1
phylosig(tree=tree.hct, x=just.hct, method="lambda", test=TRUE) # lambda=<0, p=1
phylosig(tree=tree.trbc, x=just.trbc, method="lambda", test=TRUE) # lambda=<0, p=1
phylosig(tree=tree.mcv, x=just.mcv, method="lambda", test=TRUE) # lambda=<0, p=1
phylosig(tree=tree.mch, x=just.mch, method="lambda", test=TRUE) # lambda=<0, p=1
phylosig(tree=tree.mchc, x=just.mchc, method="lambda", test=TRUE) # lambda=<0, p=1 

# --> NO PHYLO SIGNAL IN OUR DATA! 
```

Info on computing phylogenetic signal w/ Phylosig: http://blog.phytools.org/2011/03/computing-phylogenetic-signal.html


# Verify that phylo signal is robust to "sampling outliers"
How much is phylo signal affected by poorly-sampled species? To get a sense for how these species might affect estimates, let's run samples where we drop any species with n < 3 individuals, remake contmaps, and rerun tests of phylogenetic signal. 
```{r}
# # The suffix ".nso" stands for "no sampling outliers"
# 
# # Drop all species counts < 3 
# final.hb.nso <- subset(final.hb, with(final.hb, species %in% names(which(table(species)>=3)))) 
#     View(final.hb.nso %>% group_by(species) %>% summarise(count = length(nk))) # No species count < 3
# final.hct.nso <- subset(final.hct, with(final.hct, species %in% names(which(table(species)>=3)))) 
#     View(final.hct.nso %>% group_by(species) %>% summarise(count = length(nk))) 
# final.trbc.nso <- subset(final.trbc, with(final.trbc, species %in% names(which(table(species)>=3)))) 
#     View(final.trbc.nso %>% group_by(species) %>% summarise(count = length(nk))) 
# final.mcv.nso <- subset(final.mcv, with(final.mcv, species %in% names(which(table(species)>=3)))) 
#     View(final.mcv.nso %>% group_by(species) %>% summarise(count = length(nk))) 
# final.mch.nso <- subset(final.mch, with(final.mch, species %in% names(which(table(species)>=3)))) 
#     View(final.mch.nso %>% group_by(species) %>% summarise(count = length(nk))) 
# final.mchc.nso <- subset(final.mchc, with(final.mchc, species %in% names(which(table(species)>=3)))) 
#     View(final.mchc.nso %>% group_by(species) %>% summarise(count = length(nk))) 
# 
# # Set up tips to drop and drop tips from each dataset 
# hb.drop <- names(which(table(final.hb$species) < 3)) # Get names of species w/ <3 individuals 
# tree.hb.nso <- drop.tip(tree.hb, hb.drop) # Drop 
# hct.drop <- names(which(table(final.hct$species) < 3))  
# tree.hct.nso <- drop.tip(tree.hct, hct.drop) 
# trbc.drop <- names(which(table(final.trbc$species) < 3))  
# tree.trbc.nso <- drop.tip(tree.trbc, trbc.drop) 
# mcv.drop <- names(which(table(final.mcv$species) < 3))  
# tree.mcv.nso <- drop.tip(tree.mcv, mcv.drop) 
# mch.drop <- names(which(table(final.mch$species) < 3))  
# tree.mch.nso <- drop.tip(tree.mch, mch.drop) 
# mchc.drop <- names(which(table(final.mchc$species) < 3))  
# tree.mchc.nso <- drop.tip(tree.mchc, mchc.drop) 
# 
# 
# # CONTMAPS
# # HB 
# # Subset by species and mean(hb) to make trait matrix for Phytools contMap (annotations here, streamlined below)
# hb.contmap.nso <- final.hb.nso %>% group_by(species) %>% summarise(hb = mean(hb)) # HB 
# just.hb.nso <- hb.contmap.nso$hb # Take mean hb values only 
# names(just.hb.nso) <- hb.contmap.nso$species # Add sp names from hb.contmap file (to match w/ Hb); don't use rownames()! 
# hb.cont.tree.nso <- contMap(tree.hb.nso, just.hb.nso, plot=TRUE, outline=FALSE) # create Hb phylo object
# # hb.cont.tree <- setMap(hb.cont.tree, colors=c("#280a52","#e9612c","#f7d03d")) # Set colors: purple, green, yellow
# #n <- length(hb.cont.tree$cols); n # Find length of colors in contmap 
# 
# # Plot map and save to pdf w/ proper aesthetics 
# pdf(file="hemoglobin.contmap.NoSamplingOutliers.pdf", width=6, height=6)
# #hb.cont.tree$cols[1:n] <- viridis(n) # Manually set color scale to viridis 
# plot.contMap(hb.cont.tree.nso, just.hb.nso, res=200, fsize=0.4, lwd=2, leg.txt="Mean [Hb]", outline=FALSE) # Manually plot using phytools
# #par(mar=c(5.1, 4.1, 0, 2.1)) ## reset margins to default
# # Use outline=FALSE to remove black outlines from branches 
# #title("[Hb]", xpd=TRUE, ) #Add a title manually 
# #plot(hb.cont.tree, lwd=4, fsize=0.5) # setting xlim changes actual plot dimensions, NOT trait value scale 
# dev.off()
# 
# # HCT 
# hct.contmap.nso <- final.hct.nso %>% group_by(species) %>% summarise(hct = mean(hct))  
# just.hct.nso <- hct.contmap.nso$hct
# names(just.hct.nso) <- hct.contmap.nso$species 
# class(just.hct.nso); typeof(just.hct.nso) 
# hct.cont.tree.nso <- contMap(tree.hct.nso, just.hct.nso, plot=TRUE, outline=FALSE) # Make contmap object
# 
# # Plot map and save to pdf w/ proper aesthetics 
# pdf(file="hematocrit.contmap.NoSamplingOutliers.pdf", width=6, height=6) # Write plot to pdf 
# #hct.cont.tree$cols[1:n] <- viridis(n) # Manually set color scale to viridis 
# plot.contMap(hct.cont.tree.nso, just.hct.nso, res=200, fsize=0.4, lwd=2, leg.txt="Mean Hct", outline=FALSE) # Manually plot using phytools
# dev.off()
# 
# # TRBC
# trbc.contmap.nso <- final.trbc.nso %>% group_by(species) %>% summarise(trbc = mean(trbc))  
# just.trbc.nso <- trbc.contmap.nso$trbc
# names(just.trbc.nso) <- trbc.contmap.nso$species 
# class(just.trbc.nso); typeof(just.trbc.nso) 
# trbc.cont.tree.nso <- contMap(tree.trbc.nso, just.trbc.nso, plot=TRUE, outline=FALSE) # Make contmap object
# 
# # Plot map and save to pdf w/ proper aesthetics 
# pdf(file="TRBC.contmap.NoSamplingOutliers.pdf", width=6, height=6) # Write plot to pdf 
# #trbc.cont.tree$cols[1:n] <- viridis(n) # Manually set color scale to viridis 
# plot.contMap(trbc.cont.tree.nso, just.trbc.nso, res=200, fsize=0.4, lwd=2, leg.txt="Mean trbc", outline=FALSE) # Manually plot using phytools
# dev.off()
# 
# # MCV
# mcv.contmap.nso <- final.mcv.nso %>% group_by(species) %>% summarise(mcv = mean(mcv))  
# just.mcv.nso <- mcv.contmap.nso$mcv
# names(just.mcv.nso) <- mcv.contmap.nso$species 
# class(just.mcv.nso); typeof(just.mcv.nso) 
# mcv.cont.tree.nso <- contMap(tree.mcv.nso, just.mcv.nso, plot=TRUE, outline=FALSE) # Make contmap object
# 
# # Plot map and save to pdf w/ proper aesthetics 
# pdf(file="MCV.contmap.NoSamplingOutliers.pdf", width=6, height=6) # Write plot to pdf 
# #mcv.cont.tree$cols[1:n] <- viridis(n) # Manually set color scale to viridis 
# plot.contMap(mcv.cont.tree.nso, just.mcv.nso, res=200, fsize=0.4, lwd=2, leg.txt="Mean mcv", outline=FALSE) # Manually plot using phytools
# dev.off()
# 
# # MCH
# mch.contmap.nso <- final.mch.nso %>% group_by(species) %>% summarise(mch = mean(mch))  
# just.mch.nso <- mch.contmap.nso$mch
# names(just.mch.nso) <- mch.contmap.nso$species 
# class(just.mch.nso); typeof(just.mch.nso) 
# mch.cont.tree.nso <- contMap(tree.mch.nso, just.mch.nso, plot=TRUE, outline=FALSE) # Make contmap object
# 
# # Plot map and save to pdf w/ proper aesthetics 
# pdf(file="MCH.contmap.NoSamplingOutliers.pdf", width=6, height=6) # Write plot to pdf 
# #mch.cont.tree$cols[1:n] <- viridis(n) # Manually set color scale to viridis 
# plot.contMap(mch.cont.tree.nso, just.mch.nso, res=200, fsize=0.4, lwd=2, leg.txt="Mean mch", outline=FALSE) # Manually plot using phytools
# dev.off()
# 
# # MCHC
# mchc.contmap.nso <- final.mchc.nso %>% group_by(species) %>% summarise(mchc = mean(mchc))  
# just.mchc.nso <- mchc.contmap.nso$mchc
# names(just.mchc.nso) <- mchc.contmap.nso$species 
# class(just.mchc.nso); typeof(just.mchc.nso) 
# mchc.cont.tree.nso <- contMap(tree.mchc.nso, just.mchc.nso, plot=TRUE, outline=FALSE) # Make contmap object
# 
# # Plot map and save to pdf w/ proper aesthetics 
# pdf(file="MCHC.contmap.NoSamplingOutliers.pdf", width=6, height=6) # Write plot to pdf 
# #mchc.cont.tree$cols[1:n] <- viridis(n) # Manually set color scale to viridis 
# plot.contMap(mchc.cont.tree.nso, just.mchc.nso, res=200, fsize=0.4, lwd=2, leg.txt="Mean mchc", outline=FALSE) # Manually plot using phytools
# dev.off()
# 
# # TESTS OF PHYLOGENETIC SIGNAL
# # Compute two metrics of phylogenetic signal: Blomberg's K and Pagel's lamda 
# # Pagel's lambda: 0 = no phylo singal in the trait and 1 = phylo signal in the trait
# # Blomberg's K: computed w/ p-val by comparing real data to null distribution obtained by random permuations. 
#     # Values of K range from 0 to inf; K=1 = Brownian motion evol; k>1 = spp more similar than expected under random drift; 
#     # k<1 = spp less similar than expected under random drift. The larger the K, the stronger the phylo signal. 
#     # Generally, only K-values with significant p-vals indicate phylo signal
# 
# # Compute K and conduct a test of the null hypothesis of no phylogenetic signal
# set.seed(1568)
# phylosig(tree=tree.hb.nso, x=just.hb.nso, method="K", test=TRUE) # K=0.355, p=0.383
# phylosig(tree=tree.hct.nso, x=just.hct.nso, method="K", test=TRUE) # K=0.282, p=0.677
# phylosig(tree=tree.trbc.nso, x=just.trbc.nso, method="K", test=TRUE) # K=0.425, p=0.18
# phylosig(tree=tree.mcv.nso, x=just.mcv.nso, method="K", test=TRUE) # K=0.358, p=0.468
# phylosig(tree=tree.mch.nso, x=just.mch.nso, method="K", test=TRUE) # K=0.362, p=0.378
# phylosig(tree=tree.mchc.nso, x=just.mchc.nso, method="K", test=TRUE) # K=0.283, p=0.815 
# 
# # Compute Pagel's lambda using maximum likelihood
# phylosig(tree=tree.hb.nso, x=just.hb.nso, method="lambda", test=TRUE) # lambda=<0, p=1
# phylosig(tree=tree.hct.nso, x=just.hct.nso, method="lambda", test=TRUE) # lambda=<0, p=1
# phylosig(tree=tree.trbc.nso, x=just.trbc.nso, method="lambda", test=TRUE) # lambda= 0.037, p=0.934
# phylosig(tree=tree.mcv.nso, x=just.mcv.nso, method="lambda", test=TRUE) # lambda=<0, p=1
# phylosig(tree=tree.mch.nso, x=just.mch.nso, method="lambda", test=TRUE) # lambda=<0, p=1
# phylosig(tree=tree.mchc.nso, x=just.mchc.nso, method="lambda", test=TRUE) # lambda=<0, p=1 
```

**Conclusion:** Even after removing sampling outliers (species with fewer 3 individuals sampled), there is no phylogenetic signal in our data. This is confirmed visually w/ contmaps and with estimates of Pagel's lamda and Blomberg's K. 


# Check for correlations among continuous predictors 
```{r}
# Correlation matrix 
cor(final[,c("elev.z", "elev.pos.z", "temp.z", "precip.z", "mass.z", "intravar.mass.z", "intravar.temp.z", "intravar.precip.z")])

# elevation and elev_position are highly correlated (0.87) - choose to keep one and drop the other? 
# Hard to keep these both in the same model since elev_position is derived from elev 

# Elevation and tempPC1 are highly correlated (-0.83), but both are biologically important and encompass different things 
# A couple other moderate correlations, but nothing red-flaggy

# As a safeguard backup solution, you can run a model without BioClim for comparison
# see Lisa and Nora's code for this 

# This sets a global theme for all my plots. 
theme_set(theme_bw() +
            theme(
              plot.background = element_blank()
              ,panel.grid.major = element_blank()
              ,panel.grid.minor = element_blank()
              ,panel.background = element_blank()
             # ,panel.border = element_blank()
              ,axis.text.x  = element_text(angle=90, vjust=0.5, size=8)
            ))

# Take a peek at predictor scatterplot matrix: 
# p <- ggpairs(subset(final, select = c(elev.z, elev.position.z, mass.z, temp.z, precip.z, hb, hct, trbc, mcv.log, mch.log, mchc))) 
# print(p)
# commented out because not all of these are in 'final' dataset (but everything in data subsets)
```


# Save final post-processing file for modeling; this will be read into other downstream docs
```{r}
# write.csv(final, "ComparativeHummingbirdBlood_FinalDataset_ForModeling_05-27-21.csv")
```



-------


# MODELING 
*Note that in Bayesian stats, "fixed" and "random" effects don't make sense because everything can be considered random. "Grouping variable" makes more sense, as do descriptors of no, partial, or complete pooling. BUT, since "fixed" and "random" are more intuitive to a frequentist audience, I'll use those in quotes here. 

For each response, run 6 sets of models: 
1) Null (intercept only)
2) "Random effect" only (+1|species)
3) Full model (predictors only)
4) Full model + (1|species)
--
5) Reduced M3, predictors only 
6) Reduced M4, predictors + (1|species)

Select distributions and priors as is best needed for each model set. 

Note on 3/24/21: After revisiting some basic brms/Bayesian modeling material, I began to doubt whether it was appropriate to use individual-level data (referred to as "repeated measures" in the Bayesian world, implying multiple individuals sampled per species, for example) as predictors in a model since some Bayesian material suggests that predictors should be population-level. And, other resources, like this excellent vignette about incorporating repeated measures into phylogenetic brms models (https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html) suggests taking individual-level, repeated measures data and constructing "species mean" and "within species variability" variables and using these two as predictors in lieu of individual-level data (aka raw data values). 

This EXACT topic is addressed in this post: https://discourse.mc-stan.org/t/phylogenetic-model-with-repeated-measurements-without-using-species-mean/4801/4

**IN BRIEF/CONCLUSION:** Yes, the way I've structured my models is ok, and it is fine to use individual-level data as predictors. See last comment by Jon Nations (aka, might affect those conditional probabilities plots because more error is involved in individual-level measurements). Alternatively, it is also totally fine to break the data into "species mean" and "within species variability" (raw value - mean), as described in the phylo tutorial above, and Paul Buerkener says he did this following the phylogenetic textbook (Garamszagi original tutorial) from which the data originally come. So essentially: Paul modified Garamszagi's tutorial; now everyone uses Paul's tutorial, which is just one approach to a modeling challenge put forward by one guy. 

AND, the approach you use may also depend on the questions you're answering; i.e., we're interested in using elev.position, a measure of each individual's elevation relative to its species mean elevation, so "species mean" and "within species variability" variables don't capture what we want with elev.pos. 

A good lesson in "there are multiple ways to skin a cat"; questioning is good, trusting intuition is good, exploring options is good. (Plus, I did end up doing a comparison between individual-level data and population-level data (w/ predictors of spec_mean and within_species_variability) and there was essentially no difference between model results. Conditional probability plots did fit a bit better in population-level models, and R^2 was a bit higher in pop-level model, but diagnostics were all the same, and in loo model comparison, original hb.m4 emerged as the top model, marginally better than hb.popleveltest.m4)

TL;DR - We want individual-level data *and* it's totally acceptable to keep model structure the way I've been doing it from the beginning. 

As a side note, some other info about population-level modeling in brms w/ a bird malaria system someone is working on: https://discourse.mc-stan.org/t/brms-formula-for-population-level-effects-measured-at-the-group-level/20953

Repeated measures w/ population-level effects might also be helpful: https://discourse.mc-stan.org/t/repeated-measures-with-population-level-effects/10944

 
 
NOTES ON PRIORS: 

I did a lot of research on priors and I honestly think that default priors specified by brms are ok. Models fit about the same with and without weakly informative priors. 

I also think it's better to run mcv models with non-transformed MCV and skew_normal distribution - fit is better than with log-transformed MCV and gaussian. 

see if changing sample_prior=TRUE to "no" or "yes" changes results at all. 

Some stuff on priors: https://github.com/paul-buerkner/brms/issues/131

https://www.monicaalexander.com/posts/2020-28-02-bayes_viz/ <--- great brms tutorial

This has a little blurb on posteriors vs. priors: https://www.rensvandeschoot.com/tutorials/brms-priors/

brms polynomial regression: https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/linear-models.html#polynomial-regression



##### HB MODEL SET ######

# [HB] MODELS - Set up & run models 
See phylo brms tutorial here: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
```{r}
# See what prior choices are being made for us. 
get_prior(hb ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + intravar.elev.z + intravar.elev.pos.z + intravar.mass.z +  intravar.precip.z + intravar.temp.z + (1|species), data = final.hb) # removed + (1|gr(phylo, cov=A)) 

# Overwrite those (not so) terrible choices with some slightly informed priors.
# Otherwise known as 'let the data drive the model'. 
# prior1 <- c(set_prior("student_t(7, 0, 2.5)", class = "Intercept"), # Set intercept prior 
#             set_prior("student_t(3, 0, 1)", class = "b" )) # Class b = all responses 
## Need to study Ara's rationale for setting priors and maybe model my approach that way


###

# Gaussian fits better than student() for Hb models; makes sense given normality of distribution. 

# MODEL 1: NULL MODEL (INTERCEPT ONLY) 
hb.m1 <- brm(
  formula = bf(hb ~ 1),
  data = final.hb,
  family = gaussian(),
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(hb.m1, file="hb.m1_Intercept-Only.RData") # save model
#load("hb.m1_Intercept-Only.Rdata") # If loading from pre-saved file and not re-running


# MODEL 2: RANDOM EFFECTS-ONLY MODEL (INTERCEPT + SPECIES RANDOM EFFECTS)
hb.m2 <- brm(
  formula = bf(hb ~ 1 + (1|species)),
  data = final.hb,
  family = gaussian(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
#  data2 = list(A = A), # Phylogeny
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000, EBL used 10000.99, max_treedepth = 15),
  sample_prior = TRUE # save priors
)
save(hb.m2, file="hb.m2_RandomEffectsOnly.RData") # save model
# load("hb.m2_RandomEffectsOnly.RData") # If loading from pre-saved file and not re-running


# MODEL 3: FULL MODEL WITH PREDICTORS ONLY
hb.m3 <- brm(
  formula = bf(hb ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + genotype +
               intravar.mass.z + intravar.temp.z + intravar.precip.z),
  data = final.hb,
  family = gaussian(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
 # data2 = list(A = A), # Phylogeny
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(hb.m3, file="hb.m3_FullModel_PredictorsOnly.RData") # save model
# Run time: ~1 minute
# load("hb.m3_FullModel_PredictorsOnly.RData") # If loading from pre-saved file and not re-running


# MODEL 4: FULL MODEL WITH SPECIES RANDOM EFFECT
hb.m4 <- brm(
  formula = bf(hb ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + genotype +
               intravar.mass.z + intravar.temp.z + intravar.precip.z 
               + (1|species)),
  data = final.hb,
  family = gaussian(), 
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(hb.m4, file="hb.m4_FullModel_SpeciesREOnly.RData") # save model
#load("hb.m4_FullModel_SpeciesREOnly.RData") 
```


# HB: Summarize and check fit for full models (m1-m6)
Explanation of what mcmc_plot output below means: https://cran.r-project.org/web/packages/bayesplot/vignettes/plotting-mcmc-draws.html
```{r}
# FIT AND CONVERGENCE 

# Check trace plots for convergence
# Beginning will look crappy because of burn-in, but we want output to look like a "fuzzy caterpillar", aka noise is good
# Any plateaus/flat horizontal lines are bad, suggest we're sampling the same spot in the distribution repeatedly 
mcmc_plot(hb.m4, type = "trace") 
plot(hb.m4, N = 2, ask = FALSE)

# y to y-rep fit plot 
# Generate new y values given the model and compare to actual y from the data. 
# You want the y rep line to be somewhat close to dark line, signifying that model fits the data
bayesplot::pp_check(hb.m4, resp = "hb", nsamples = 100) # pull 100 draws from model and cast back to original data 
bayesplot::pp_check(hb.m4, type = "stat", stat = 'median', nsamples = 100)

# Is there presence of strong autocorrelation?
# If you have autocorrelation, you get a bunch of red things flagged 
# 1, 2, 3, 4, are chains = all 4 behaving more or less the same 
# you'd see a bright red bar if something is out of whack
# Pale bars = you want all heading towards zero to show they're not correlating w/ each other across the chains 
# fine to be pos and neg, jumping around to get to zero
mcmc_plot(hb.m4, type = "acf_bar")

# plot conditional effects for full model (note: you do this separately below)
# Note: this used to be called marginal_effects, but that's now deprecated; replaced w/ conditional_effects
# nu = degrees of freedom
plot(conditional_effects(hb.m4), points = TRUE) 

# Quick plot of estimates and 95% CIs (default is 95% CI:
mcmc_plot(hb.m4)  # adjust prob to get 95% CI

# Changes the fixed effects (i.e. random variable) to odd's ratio 
#exp(fixef(hb.m4)[,-2])

# Print group level variable (in log odds)
# ranef is still an array, so not an exponent on it, hard to change to probability estimates 
ranef(hb.m4, groups="species") #, probs = 0.95)

# Residual plots 
# typical residual plot but w/ addition of uncertainty associated w/ each residual given by generating draws from the dist 
# associated with each residual
final.hb %>%
  add_residual_draws(hb.m4) %>%
  ggplot(aes(x = .row, y = .residual)) +
  stat_pointinterval()

# qqPlots
# final.hb %>% # Simple qqplot; one below is best 
#   add_residual_draws(hb.m4) %>%
#   median_qi() %>%
#   ggplot(aes(sample = .residual)) +
#   geom_qq() +
#   geom_qq_line()

final.hb %>%
  add_predicted_draws(hb.m4) %>%
  summarise(
    p_residual = mean(.prediction < hb), # probability residual; Bayesian predictive p-value 
    z_residual = qnorm(p_residual) # quantile residuals 
  ) %>%
  ggplot(aes(sample = z_residual)) +
  geom_qq() +
  geom_abline()
# If predicted distribution is uniform, probabilities should be well calibrated
```



# Hb: Plot outputs of posterior mean estimates and 95% credible intervals (full models, m1-m6)
```{r}
# Plot: Posterior mean estimates and 95% credible intervals for predictors.
# Plot these nicely and without intercepts, which throws off scale: 
# This is a graphical way to look at model fit as opposed to just dumping out model output
# Circle = point estimate (model summary, print(hb.m6))
# Thin bars = default 90% CI; adjust prob_outer=0.95 to get 95% CI 
# Thick bars = default 50% CI; adjust prob=0.50 to get anything else 
# x-axis should be scale based on value of estimates coming out of the model 

# Model 3 
#pairs(hb.m3)
color_scheme_set("blue") # nice default
hb.m3.p1 <- mcmc_plot(hb.m3, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
                                    "b_genotypeGlyMSer", "b_genotypeSerMSer",
                                    "b_intravar.mass.z", "b_intravar.temp.z", "b_intravar.precip.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [Hb]", title = "hb.m3: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation","Elevation Position","Mass", "Temp", "Precip", "Genotype (Gly-Ser)", "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip"))  
hb.m3.p1
ggsave(hb.m3.p1, filename = "hb.m3.p1_Hb_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(hb.m3)
# Predictors whose 95% CIs do NOT overlap zero (what reduced model will be): elev.z, mass.z, temp.z, intravar.temp.z

# Model 4
#color_scheme_set("red") # nice default
hb.m4.p1 <- mcmc_plot(hb.m4, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
                                    "b_genotypeGlyMSer", "b_genotypeSerMSer",
                                    "b_intravar.mass.z", "b_intravar.temp.z", "b_intravar.precip.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [Hb]", title = "hb.m4: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation","Elevation Position","Mass", "Temp", "Precip", "Genotype (Gly-Ser)", "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip"))   
hb.m4.p1
ggsave(hb.m4.p1, filename = "hb.m4.p1_Hb_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(hb.m4)
# Predictors whose 95% CIs do NOT overlap zero (what reduced model will be): elev.z

####

# Summary of reducing models: 
# m5 (reduced m3) will be: elev.z, mass.z, temp.z, intravar.temp.z
# m6 (reduced m4) will be: elev.z
```


# Hb: Collate model summaries and WAIC scores for full models (m1-m6)
```{r}
# Print model summaries 
sink("hb_brms_model_summaries.txt",append = TRUE)
summary(hb.m1, waic=TRUE)
summary(hb.m2, waic=TRUE)
summary(hb.m3, waic=TRUE)
summary(hb.m4, waic=TRUE)
sink()
# print(hb.test, prob=0.95) # change CI cut-off by adjusting prob; remember Bayesian default may not be 95%

# Get model WAIC scores  
hb.m1.waic <- waic(hb.m1)
hb.m2.waic <- waic(hb.m2)
hb.m3.waic <- waic(hb.m3)
hb.m4.waic <- waic(hb.m4)
hb.waics <- cbind(hb.m1.waic, hb.m2.waic, hb.m3.waic, hb.m4.waic); hb.waics
write.csv(hb.waics, "hb_brms_models_waics.csv") # totally unintelligible cumbersome doc w/ all pointwise comparisons 
```


# Hb: Calculate variance explained by species effect full models (m2, m4)
Calculated from Burkner's phylo  brms tutorial: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
Note from Burkner: Note that the phylogenetic signal is just a synonym of the intra-class correlation (ICC) used in the context phylogenetic analysis.
```{R}
# CALCULATE INTRACLASS CORRELATION (ICC) EXPLAINED BY SPECIES GROUPING VARIABLE 
# ICC = Tells you proportion of total variance in response variable that is acccounted for by species identity (i.e. clustering)

# m2 
hyp.sp.hb.m2 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.hb.m2 <- hypothesis(hb.m2, hyp.sp.hb.m2, class = NULL))
plot(hyp.sp.hb.m2)
# ~17% variance explained 

# m4 species variance 
hyp.sp.hb.m4 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.hb.m4 <- hypothesis(hb.m4, hyp.sp.hb.m4, class = NULL))
plot(hyp.sp.hb.m4)
# 13% variance explained by species 

performance::variance_decomposition(hb.m4)
performance::variance_decomposition(hb.m2)
```


# Hb: RUN REDUCED MODELS (m5-m6)
```{r}
# MODEL 5: REDUCED MODEL WITH NO RANDOM EFFECTS (JUST PREDICTORS)
hb.m5 <- brm(
  formula = bf(hb ~ 1 + elev.z + mass.z + temp.z + intravar.temp.z), 
  data = final.hb,
  family = gaussian(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, # default is iter/2; shouldn't ever be larger than iter
  iter = 10000, 
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(hb.m5, file="hb.m5_ReducedModel_PredictorsOnly.RData") # save model
#load("hb.m5_ReducedModel_PredictorsOnly.RData") # If loading from pre-saved file and not re-running

# MODEL 6: REDUCED MODEL WITH ONLY SPECIES RANDOM EFFECT
hb.m6 <- brm(
  formula = bf(hb ~ 1 + elev.z + (1|species)),
  data = final.hb,
  family = gaussian(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
 # data2 = list(A = A), # Phylogeny
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, # default is iter/2; shouldn't ever be larger than iter
  iter = 10000, 
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(hb.m6, file="hb.m6_ReducedModel_SpeciesREOnly.RData") # save model
# load("hb.m6_ReducedModel_SpeciesREOnly.RData") 
```


# HB: Summarize and check fit for reduced models (m5-m6)
Explanation of what mcmc_plot output below means: https://cran.r-project.org/web/packages/bayesplot/vignettes/plotting-mcmc-draws.html
```{r}
# FIT AND CONVERGENCE 

# Check trace plots for convergence
# Beginning will look crappy because of burn-in, but we want output to look like a "fuzzy caterpillar", aka noise is good
# Any plateaus/flat horizontal lines are bad, suggest we're sampling the same spot in the distribution repeatedly 
mcmc_plot(hb.m6, type = "trace") 
plot(hb.m6, N = 2, ask = FALSE)

# y to y-rep fit plot 
# Generate new y values given the model and compare to actual y from the data. 
# You want the y rep line to be somewhat close to dark line, signifying that model fits the data
bayesplot::pp_check(hb.m6, resp = "hb", nsamples = 100) # pull 100 draws from model and cast back to original data 
bayesplot::pp_check(hb.m6, type = "stat", stat = 'median', nsamples = 100)


# Is there presence of strong autocorrelation?
# If you have autocorrelation, you get a bunch of red things flagged 
# 1, 2, 3, 4, are chains = all 4 behaving more or less the same 
# you'd see a bright red bar if something is out of whack
# Pale bars = you want all heading towards zero to show they're not correlating w/ each other across the chains 
# fine to be pos and neg, jumping around to get to zero
mcmc_plot(hb.m6, type = "acf_bar")

# plot conditional effects for full model (note: you do this separately below)
# Note: this used to be called marginal_effects, but that's now deprecated; replaced w/ conditional_effects
# nu = degrees of freedom
plot(conditional_effects(hb.m6), points = TRUE) 

# Quick plot of estimates and 95% CIs (default is 95% CI:
mcmc_plot(hb.m6)  # adjust prob to get 95% CI

# Changes the fixed effects (i.e. random variable) to odd's ratio 
exp(fixef(hb.m6)[,-2])

# Print group level variable (in log odds)
# ranef is still an array, so not an exponent on it, hard to change to probability estimates 
ranef(hb.m6, groups="species") #, probs = 0.95)

# Residual plots 
# typical residual plot but w/ addition of uncertainty associated w/ each residual given by generating draws from the dist 
# associated with each residual
final.hb %>%
  add_residual_draws(hb.m6) %>%
  ggplot(aes(x = .row, y = .residual)) +
  stat_pointinterval()

# qqPlots
final.hb %>%
  add_predicted_draws(hb.m6) %>%
  summarise(
    p_residual = mean(.prediction < hb), # probability residual; Bayesian predictive p-value 
    z_residual = qnorm(p_residual) # quantile residuals 
  ) %>%
  ggplot(aes(sample = z_residual)) +
  geom_qq() +
  geom_abline()
# If predicted distribution is uniform, probabilities should be well calibrated
```


# Hb: Plot outputs of posterior mean estimates and 95% credible intervals (full models, m1-m6)
```{r}
# Plot: Posterior mean estimates and 95% credible intervals for predictors.
# Plot these nicely and without intercepts, which throws off scale: 
# This is a graphical way to look at model fit as opposed to just dumping out model output
# Circle = point estimate (model summary, print(hb.m6))
# Thin bars = default 90% CI; adjust prob_outer=0.95 to get 95% CI 
# Thick bars = default 50% CI; adjust prob=0.50 to get anything else 
# x-axis should be scale based on value of estimates coming out of the model 

# Model 5 
color_scheme_set("blue") # nice default
hb.m5.p1 <- mcmc_plot(hb.m5, pars=c("b_elev.z", "b_mass.z", "b_temp.z", "b_intravar.temp.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [Hb]", title = "hb.m5: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elev", "Mass", "Temperature", "Intravar: Temp"))  
hb.m5.p1
ggsave(hb.m5.p1, filename = "hb.m5.p1_Hb_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(hb.m5)

# Model 6
#color_scheme_set("red") # nice default
hb.m6.p1 <- mcmc_plot(hb.m6, pars=c("b_elev.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [Hb]", title = "hb.m6: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation"))   
hb.m6.p1
ggsave(hb.m6.p1, filename = "hb.m6.p1_Hb_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(hb.m6)
```


# Hb: Collate model summaries and WAIC scores for reduced models (m5-m6)
```{r}
# Print model summaries 
sink("hb_reduced_brms_model_summaries.txt",append = TRUE)
summary(hb.m5, waic=TRUE)
summary(hb.m6, waic=TRUE)
sink()
# print(hb.test, prob=0.95) # change CI cut-off by adjusting prob; remember Bayesian default may not be 95%

# Get model WAIC scores  
hb.m5.waic <- waic(hb.m5)
hb.m6.waic <- waic(hb.m6)
hb.waics.red <- cbind(hb.m5.waic, hb.m6.waic); hb.waics.red
write.csv(hb.waics.red, "hb_brms_models_waics.red.csv") # totally unintelligible cumbersome doc w/ all pointwise comparisons
```


# Hb: CALCULATE INTRACLASS CORRELATION (ICC) EXPLAINED BY SPECIES GROUPING VARIABLE
Calculated from Burkner's phylo  brms tutorial: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
Note from Burkner: Note that the phylogenetic signal is just a synonym of the intra-class correlation (ICC) used in the context phylogenetic analysis.
```{R}
# ICC = Tells you proportion of total variance in response variable that is acccounted for by species identity (i.e. clustering)

# m6 species variance 
hyp.sp.hb.m6 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.hb.m6 <- hypothesis(hb.m6, hyp.sp.hb.m6, class = NULL))
plot(hyp.sp.hb.m6)
# 17% variance explained by species 
```


# HB: MODEL COMPARISON 
```{r}
# leave one out cross-validation, lowest is "best"
# if 2*standard error > delta LOOIC, models aren't necessarily distinguishable

library(loo)
sink("hb_brms_models_all_looic.txt", append=FALSE)
LOO(hb.m1, hb.m2, hb.m3, hb.m4, hb.m5, hb.m6, reloo=FALSE) 
sink()
# According to LOO, model 5 is top model 

# compare models # Just a shorter version of the above text
# loo_compare(en.loo) # Top ranked model includes no random effects 

# Calculate Bayesian R^2:
bayes_R2(hb.m1)
bayes_R2(hb.m2) # 0.146
bayes_R2(hb.m3) # 0.130
bayes_R2(hb.m4) # 0.209
bayes_R2(hb.m5) # 0.116
bayes_R2(hb.m6) # 0.192

# Model comparisons:
#       elpd_diff se_diff
# hb.m4   0.0       0.0  
# hb.m6  -3.3       4.2  
# hb.m2 -29.0       8.4  
# hb.m5 -29.7       8.8  
# hb.m3 -29.9       7.6  
# hb.m1 -85.5      13.1  

# Now re-run top model with unstandardized predictors to estimate strength of relationship between Xs and y:
job::job({ # Send to a job to free up console
hb.m4.unstandardized <- 
  update(hb.m4,
        newdata = final.hb,
        formula = hb ~ 1 + elev + elev_position + mass.log + tempPC1 + precipPC1 + genotype + # use non .z names!!!!
               intravar.mass + intravar.temp + intravar.precip + (1|species),
        chains = 4, cores = 4)
save(hb.m4.unstandardized, file="hb.m4.unstandardized_Predictors_SpeciesRE.RData") # save model
})
# load("hb.m4.unstandardized_Predictors_SpeciesRE.RData")

# Look at magnitude of unstandardized coefficients 
summary(hb.m4.unstandardized)
fixef(hb.m4.unstandardized)[2] # For every 1 m increase in elev, we expect Hb will increase by 0.0003885536
round(fixef(hb.m4.unstandardized)[2]*1000, 2) # For every 1000m increase in elev, [Hb] will increase by 0.39 g/dl. 
fixef(hb.m4.unstandardized)[3] # elev_position
# Not sure if other variables are worth reporting, as they have really obscure units
```

Quick summary of top 3 models in order of ranking: 
1) Model 4: Full model + (1|species) **significantly better than other models, 13% variance explained by species 
2) Model 6: Reduced model w/ just elvation and +1 species, 17% variation explained by species 
3) Model 2: Null + (1|species), 17% of variance explained by species 

**All models fit substantially better than the intercept-only model (m1), AND, it's very clear that it's important to consider variation explained by species identity. 




Hb test of posterior draws plot

Helpful Tidybayes spread_draws tutorial: https://cran.r-project.org/web/packages/tidybayes/vignettes/tidy-brms.html
```{r}
# example model
m_mpg = brm(
  mpg ~ log(hp), 
  data = mtcars, 
  family = lognormal,

  file = "README_models/m_mpg.rds" # cache model (can be removed)  
)

library(modelr)
library(ggdist)
library(tidybayes)

mtcars %>%
  data_grid(hp = seq_range(hp, n = 101)) %>%
  add_predicted_draws(m_mpg) %>%
  ggplot(aes(x = hp, y = mpg)) +
  stat_lineribbon(aes(y = .prediction), .width = c(.99, .95, .8, .5), color = "#08519C") +
  geom_point(data = mtcars, size = 2) +
  scale_fill_brewer()

predicted_draws(hb.m4)
get_variables(hb.m4)
# b_Intercept is global mean; r_condition[] variables are offsets from that mean for each condition

# Spread model draws
hb.m4 %>%
  spread_draws(r_species[species,term]) %>% # changing names in square brackets just changes column headers 
  head(10)


hb.m4 %>%
  spread_draws(b_Intercept, sigma) %>% # Extract draws corresponding to overall mean (Intercept) and standard dev (sigma)
  head(10)

hb.m4 %>%
  spread_draws(b_Intercept, sigma) %>%
  median_qi(b_Intercept, sigma) %>% # add in median and 95% quantile of variables
  head(10)

# Make a long list instead: 
hb.m4 %>%
  gather_draws(b_Intercept, sigma) %>%
  median_qi()

hb.m4 %>%
  spread_draws(r_species[species,]) %>% # spread_draws automatically groups by condition
  median_qi()

hb.m4 %>% 
  spread_draws(b_Intercept, r_species[species,]) %>%
  head(10)

# Within each draw, b_Intercept is repeated as necessary to correspond to every index of r_condition. Thus, the mutate function from dplyr can be used to find their sum, condition_mean (which is the mean for each condition):

hb.m4 %>%
  spread_draws(`b_Intercept`, r_species[species,]) %>% # get species means 
  mutate(species_mean = b_Intercept + r_species) %>%
  median_qi(species_mean)

# Plot point summary with one interval
hb.m4 %>%
  spread_draws(b_Intercept, r_species[species,]) %>%
  median_qi(species_mean = b_Intercept + r_species) %>%
  ggplot(aes(y = species, x = species_mean, xmin = .lower, xmax = .upper)) +
  geom_pointinterval()
# Can you plot this in order of phylogeny? 

# Intervals with multiple probability levels: 
hb.m4 %>%
  spread_draws(b_Intercept, r_species[species,]) %>%
  median_qi(species_mean = b_Intercept + r_species, .width = c(.95, .8, .5))
# The results are in a tidy format: one row per group and uncertainty interval width (.width). 
# This facilitates plotting

hb.m4 %>%
  spread_draws(b_Intercept, r_species[species,]) %>%
  median_qi(species_mean = b_Intercept + r_species, .width = c(.95, .66)) %>%
  ggplot(aes(y = species, x = species_mean, xmin = .lower, xmax = .upper)) +
  geom_pointinterval() 

# Intervals with densities: 
hb.m4 %>%
  spread_draws(b_Intercept, r_species[species,]) %>%
  mutate(species_mean = b_Intercept + r_species) %>%
  ggplot(aes(y = species, x = species_mean)) +
  stat_halfeye()
# not a great look for what I'm doing - too many groups

# 
hb.m4 %>%
  spread_draws(b_Intercept, r_species[species,]) %>%
  mutate(species_mean = b_Intercept + r_species) %>%
  ggplot(aes(y = species, x = species_mean, fill = stat(abs(x) < .8))) +
  stat_halfeye() +
  geom_vline(xintercept = c(16, 20), linetype = "dashed") +
  scale_fill_manual(values = c("gray80", "skyblue"))

# add posterior draws 

final.hb %>%
  data_grid(species) %>%
  add_fitted_draws(hb.m4) %>%
  head(10)


final.hb %>%
  data_grid(elev.z) %>%
  add_predicted_draws(hb.m3) %>% #specify model you want draws from 
  ggplot(aes(x = elev, y = hb)) +
  stat_lineribbon(aes(y = .prediction), .width = c(.99, .95, .8, .5), color = "#08519C") +
  geom_point(data = final.hb, size = 2) +
  scale_fill_brewer()

final.mcv %>%
  data_grid(temp.z, species) %>%
  add_predicted_draws(mcv.m6) %>%
  ggplot(aes(x = .prediction, y = temp.z)) +
  stat_slab()


final.hb %>%
  group_by(species) %>%
  data_grid(hb = seq_range(hb, n = 51)) %>%
  add_fitted_draws(hb.m4) %>%
  ggplot(aes(x = hb, y = hb, color = ordered(species))) +
  stat_lineribbon(aes(y = .value)) +
  geom_point(data = final.hb) +
  scale_fill_brewer(palette = "Greys") +
  scale_color_brewer(palette = "Set2")

# compare levels - pairwise comparison between species is essentially meaningless
hb.m4 %>%
  spread_draws(r_species[species,]) %>%
  compare_levels(r_species, by = species) %>%
  ggplot(aes(y = species, x = r_species)) +
  stat_halfeye()

hb.m4 %>%
  spread_draws(r_species[species,]) %>%
  compare_levels(r_species, by = species) %>%
  ggplot(aes(y = species, x = r_species)) +
  stat_halfeye()


# Or let's plot comparisons of all levels of j within
# all levels of i
hb.m4 %>%
  spread_draws(b[genotype,genotype]) %>%
  group_by(i) %>%
  compare_levels(b, by = j) %>%
  ggplot(aes(x = b, y = j)) +
  stat_halfeye() +
  facet_grid(cols = vars(i))

# Or let's plot all comparisons against the first level (control):
hb.m4 %>%
  spread_draws(b[i,genotype]) %>%
  filter(genotype == 1) %>%
  compare_levels(b, by = i, comparison = control) %>%
  ggplot(aes(x = b, y = i)) +
  stat_halfeye()

# export draws from sampled posterior
hb.m4.draws %>%
gather_draws("b_elev.z", "b_elev.pos.z", "b_mass.z", "b_temp.z", "b_precip.z", "b_genotypeGlyMSer", "b_genotypeSerMSer", "b_intravar.mass.z", "b_intravar.temp.z", "b_intravar.precip.z") %>%
write.csv("hb.m4.draws.csv")

# Do as EBL did: use gather_draws to make a gathered data frame
# then use his code to plot

p20 <- ggplot(final.hb, aes(x = elevation, y = Hb)) +
  geom_ribbon(aes(ymin = p_ll, ymax = p_ul),
              fill = "gray10", alpha = 1/5) +
  geom_smooth(aes(ymin = f_ll, ymax = f_ul),
              stat = "identity",
              fill = "gray10", color = "gray40", alpha = 1/5, size = 1/4) +
  geom_point(data=slope_df_m, aes(x=elev_range_s, y=slope_hb), pch=21) +
  coord_cartesian(xlim = range(slope_df_m$elev_range_s),
                  ylim = range(slope_df_m$slope_hb)) +
  labs(y = expression(paste(Delta, " [Hb] * ",10^{3})),
       x  = "Elevational Range Breadth (Standardized)") +
  theme_bw() +
  theme(panel.grid = element_blank())  
p20


```






##### HCT MODEL SET #######


# [HCT] MODELS - Set up & run models 
See phylo brms tutorial here: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
```{r}
# See what prior choices are being made for us. 
get_prior(hct ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + intravar.mass.z + intravar.precip.z + intravar.temp.z + (1|species), data = final.hct)

###

# For each response variable, run 10 sets of models 
# These first 6 models represent full models; after this, I'll assess fit and then run reduced models 
# Note: I don't think we want random effect of sex because we have many unknowns! 
# Gaussian appears to fit better than student's t distribution

# MODEL 1: NULL MODEL (INTERCEPT ONLY) 
hct.m1 <- brm(
  formula = bf(hct ~ 1),
  data = final.hct,
  family = gaussian(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
#  data2 = list(A = A), # Phylogeny
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000, EBL used 10000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
  # prior = c(
  #   prior(normal(0, 10), "b"),
  #   prior(normal(3, 20, 5), "Intercept"),
  #   prior(student_t(3, 0, 5), "sd"),
  #   prior(student_t(3, 0, 5), "sigma") # sigma = standard deviation
  # )
)
save(hct.m1, file="hct.m1_Intercept-Only.RData") # save model
# load("hct.m1_Intercept-Only.Rdata") 


# MODEL 2: RANDOM EFFECTS-ONLY MODEL (INTERCEPT + PHYLO & SPECIES RANDOM EFFECTS)
hct.m2 <- brm(
  formula = bf(hct ~ 1 + (1|species)),
  data = final.hct,
  family = gaussian(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
#  data2 = list(A = A), # Phylogeny
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000, EBL used 10000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
  # prior = c(
  #   prior(normal(0, 10), "b"),
  #   prior(normal(3, 20, 5), "Intercept"),
  #   prior(student_t(3, 0, 5), "sd"),
  #   prior(student_t(3, 0, 5), "sigma") # sigma = standard deviation
  # )
)
save(hct.m2, file="hct.m2_RandomEffectsOnly.RData") # save model
#load("hct.m2_RandomEffectsOnly.RData") # If loading from pre-saved file and not re-running


# MODEL 3: FULL MODEL WITH NO RANDOM EFFECTS (JUST PREDICTORS)
hct.m3 <- brm(
  formula = bf(hct ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + genotype +
               intravar.mass.z + intravar.temp.z + intravar.precip.z),
  data = final.hct,
  family = gaussian(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
 # data2 = list(A = A), # Phylogeny
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000, EBL used 10000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
  # prior = c(
  #   prior(normal(0, 10), "b"),
  #   prior(normal(3, 20, 5), "Intercept"),
  #   prior(student_t(3, 0, 5), "sd"),
  #   prior(student_t(3, 0, 5), "sigma") # sigma = standard deviation
  # )
)
save(hct.m3, file="hct.m3_FullModel_PredictorsOnly.RData") # save model
# Run time: ~1 minute
# load("hct.m3_FullModel_PredictorsOnly.RData") # If loading from pre-saved file and not re-running


# MODEL 4: FULL MODEL WITH ONLY SPECIES RANDOM EFFECT
hct.m4 <- brm(
  formula = bf(hct ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + genotype +
               intravar.mass.z + intravar.temp.z + intravar.precip.z 
               + (1|species)),
  data = final.hct,
  family = gaussian(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
 # data2 = list(A = A), # Phylogeny
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000, EBL used 10000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
  # prior = c(
  #   prior(normal(0, 10), "b"),
  #   prior(normal(3, 20, 5), "Intercept"),
  #   prior(student_t(3, 0, 5), "sd"),
  #   prior(student_t(3, 0, 5), "sigma") # sigma = standard deviation
  # )
)
save(hct.m4, file="hct.m4_FullModel_SpeciesREOnly.RData") # save model
# load("hct.m4_FullModel_SpeciesREOnly.RData") 

# I tried running a test version of model 6 without intraspecific variation variables
# Nothing qualitatively changed, *and*, I don't think that's appropriate because modeling within-sp variation is important
```


# hct: Summarize and check fit for full models (m1-m6)
Explanation of what mcmc_plot output below means: https://cran.r-project.org/web/packages/bayesplot/vignettes/plotting-mcmc-draws.html
```{r}
# FIT AND CONVERGENCE 

# Check trace plots for convergence
# Beginning will look crappy because of burn-in, but we want output to look like a "fuzzy caterpillar", aka noise is good
# Any plateaus/flat horizontal lines are bad, suggest we're sampling the same spot in the distribution repeatedly 
mcmc_plot(hct.m4, type = "trace") 
plot(hct.m4, N = 2, ask = FALSE)

# y to y-rep fit plot 
# Generate new y values given the model and compare to actual y from the data. 
# You want the y rep line to be somewhat close to dark line, signifying that model fits the data
bayesplot::pp_check(hct.m4, resp = "hct", nsamples = 100) # pull 100 draws from model and cast back to original data 
bayesplot::pp_check(hct.m4, type = "stat", stat = 'median', nsamples = 100)

# Is there presence of strong autocorrelation?
# If you have autocorrelation, you get a bunch of red things flagged 
# 1, 2, 3, 4, are chains = all 4 behaving more or less the same 
# you'd see a bright red bar if something is out of whack
# Pale bars = you want all heading towards zero to show they're not correlating w/ each other across the chains 
# fine to be pos and neg, jumping around to get to zero
mcmc_plot(hct.m4, type = "acf_bar")

# plot conditional effects for full model (note: you do this separately below)
# Note: this used to be called marginal_effects, but that's now deprecated; replaced w/ conditional_effects
# nu = degrees of freedom
plot(conditional_effects(hct.m4), points = TRUE) 

# Quick plot of estimates and 95% CIs (default is 95% CI:
mcmc_plot(hct.m4)  # adjust prob to get 95% CI

# Changes the fixed effects (i.e. random variable) to odd's ratio 
# exp(fixef(hct.m4)[,-2])

# Print group level variable (in log odds)
# ranef is still an array, so not an exponent on it, hard to change to probability estimates 
ranef(hct.m4, groups="species") #, probs = 0.95)

# Residual plots 
# typical residual plot but w/ addition of uncertainty associated w/ each residual given by generating draws from the dist 
# associated with each residual
final.hct %>%
  add_residual_draws(hct.m4) %>%
  ggplot(aes(x = .row, y = .residual)) +
  stat_pointinterval()

# qqPlots
final.hct %>%
  add_predicted_draws(hct.m4) %>%
  summarise(
    p_residual = mean(.prediction < hct), # probability residual; Bayesian predictive p-value 
    z_residual = qnorm(p_residual) # quantile residuals 
  ) %>%
  ggplot(aes(sample = z_residual)) +
  geom_qq() +
  geom_abline()
# If predicted distribution is uniform, probabilities should be well calibrated
```


# hct: Plot outputs of posterior mean estimates and 95% credible intervals (full models, m1-m6)
```{r}
# Plot: Posterior mean estimates and 95% credible intervals for predictors.
# Plot these nicely and without intercepts, which throws off scale: 
# This is a graphical way to look at model fit as opposed to just dumping out model output
# Circle = point estimate (model summary, print(hct.m6))
# Thin bars = default 90% CI; adjust prob_outer=0.95 to get 95% CI 
# Thick bars = default 50% CI; adjust prob=0.50 to get anything else 
# x-axis should be scale based on value of estimates coming out of the model 

# Model 3 
color_scheme_set("blue") # nice default
hct.m3.p1 <- mcmc_plot(hct.m3, pars=c("b_elev.z", "b_elev.pos.z", "b_mass.z","b_temp.z","b_precip.z",
                                    "b_genotypeGlyMSer", "b_genotypeSerMSer",
                                    "b_intravar.mass.z", "b_intravar.temp.z", "b_intravar.precip.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [hct]", title = "hct.m3: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation","Elevation Position", "Mass", "Temp", "Precip", "Genotype (Gly-Ser)", "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip"))  
hct.m3.p1
ggsave(hct.m3.p1, filename = "hct.m3.p1_hct_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(hct.m3)
# Predictors whose 95% CIs do NOT overlap zero (will appear in reduced model_: elev.z, elev.pos.z, mass.z, intravar.mass.z, temp.z

# Model 4
#color_scheme_set("red") # nice default
hct.m4.p1 <- mcmc_plot(hct.m4, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
                                    "b_genotypeGlyMSer", "b_genotypeSerMSer",
                                    "b_intravar.mass.z", "b_intravar.temp.z", "b_intravar.precip.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [hct]", title = "hct.m4: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation","Elevation Position", "Mass", "Temp", "Precip", "Genotype (Gly-Ser)", "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip"))   
hct.m4.p1
ggsave(hct.m4.p1, filename = "hct.m4.p1_hct_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(hct.m4)
# Predictors whose 95% CIs do NOT overlap zero (that will be in reduced model): elev.z + elev.pos.z + intravar.mass.z

####

# Summary of reducing models: 
# m5 (reduced m3) will be: elev.z, elev.pos.z, mass.z, intravar.mass.z, temp.z 
# m6 (reduced m4) will be: elev.z + elev.pos.z, intravar.mass.z
```

# hct: Collate model summaries and WAIC scores for full models (m1-m6)
```{r}
# Print model summaries 
sink("hct_brms_model_summaries.txt",append = TRUE)
summary(hct.m1, waic=TRUE)
summary(hct.m2, waic=TRUE)
summary(hct.m3, waic=TRUE)
summary(hct.m4, waic=TRUE)
sink()
# print(hct.test, prob=0.95) # change CI cut-off by adjusting prob; remember Bayesian default may not be 95%

# Get model WAIC scores  
hct.m1.waic <- waic(hct.m1)
hct.m2.waic <- waic(hct.m2)
hct.m3.waic <- waic(hct.m3)
hct.m4.waic <- waic(hct.m4)
hct.waics <- cbind(hct.m1.waic, hct.m2.waic, hct.m3.waic, hct.m4.waic); hct.waics
write.csv(hct.waics, "hct_brms_models_waics.csv") # totally unintelligible cumbersome doc w/ all pointwise comparisons 
```


# hct: CALCULATE INTRACLASS CORRELATION (ICC) EXPLAINED BY SPECIES GROUPING VARIABLE (models 2, 4)
Calculated from Burkner's phylo  brms tutorial: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
Note from Burkner: Note that the phylogenetic signal is just a synonym of the intra-class correlation (ICC) used in the context phylogenetic analysis.
```{R}
# ICC = Tells you proportion of total variance in response variable that is acccounted for by species identity (i.e. clustering)

# m2 
hyp.sp.hct.m2 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.hct.m2 <- hypothesis(hct.m2, hyp.sp.hct.m2, class = NULL))
plot(hyp.sp.hct.m2)
# 14% variance explained 

# m4 species variance 
hyp.sp.hct.m4 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.hct.m4 <- hypothesis(hct.m4, hyp.sp.hct.m4, class = NULL))
plot(hyp.sp.hct.m4)
# 13% variance explained by species 
```


# hct: RUN REDUCED MODELS (m5-6)
```{r}
# MODEL 5: REDUCED MODEL WITH NO RANDOM EFFECTS (JUST PREDICTORS)
hct.m5 <- brm(
  formula = bf(hct ~ 1 + elev.z + elev.pos.z + mass.z + intravar.mass.z + temp.z),
  data = final.hct,
  family = gaussian(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
 # data2 = list(A = A), # Phylogeny
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, # default is iter/2; shouldn't ever be larger than iter
  iter = 10000, 
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(hct.m5, file="hct.m5_ReducedModel_PredictorsOnly.RData") # save model
# load("hct.m5_ReducedModel_PredictorsOnly.RData") # If loading from pre-saved file and not re-running

# MODEL 6: REDUCED MODEL WITH ONLY SPECIES RANDOM EFFECT
hct.m6 <- brm(
  formula = bf(hct ~ 1 + elev.z + elev.pos.z + intravar.mass.z + (1|species)),
  data = final.hct,
  family = gaussian(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
 # data2 = list(A = A), # Phylogeny
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, # default is iter/2; shouldn't ever be larger than iter
  iter = 10000, 
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(hct.m6, file="hct.m6_ReducedModel_SpeciesREOnly.RData") # save model
# load("hct.m6_ReducedModel_SpeciesREOnly.RData") 
```


# hct: Summarize and check fit for reduced models (m5-m6)
Explanation of what mcmc_plot output below means: https://cran.r-project.org/web/packages/bayesplot/vignettes/plotting-mcmc-draws.html
```{r}
# FIT AND CONVERGENCE 

# Check trace plots for convergence
# Beginning will look crappy because of burn-in, but we want output to look like a "fuzzy caterpillar", aka noise is good
# Any plateaus/flat horizontal lines are bad, suggest we're sampling the same spot in the distribution repeatedly 
mcmc_plot(hct.m6, type = "trace") 
plot(hct.m6, N = 2, ask = FALSE)

# y to y-rep fit plot 
# Generate new y values given the model and compare to actual y from the data. 
# You want the y rep line to be somewhat close to dark line, signifying that model fits the data
bayesplot::pp_check(hct.m6, resp = "hct", nsamples = 100) # pull 100 draws from model and cast back to original data 
bayesplot::pp_check(hct.m6, type = "stat", stat = 'median', nsamples = 100)

# Is there presence of strong autocorrelation?
# If you have autocorrelation, you get a bunch of red things flagged 
# 1, 2, 3, 4, are chains = all 4 behaving more or less the same 
# you'd see a bright red bar if something is out of whack
# Pale bars = you want all heading towards zero to show they're not correlating w/ each other across the chains 
# fine to be pos and neg, jumping around to get to zero
mcmc_plot(hct.m6, type = "acf_bar")

# plot conditional effects for full model (note: you do this separately below)
# Note: this used to be called marginal_effects, but that's now deprecated; replaced w/ conditional_effects
# nu = degrees of freedom
plot(conditional_effects(hct.m6), points = TRUE) 

# Quick plot of estimates and 95% CIs (default is 95% CI:
mcmc_plot(hct.m6)  # adjust prob to get 95% CI

# Changes the fixed effects (i.e. random variable) to odd's ratio 
exp(fixef(hct.m6)[,-2])

# Print group level variable (in log odds)
# ranef is still an array, so not an exponent on it, hard to change to probability estimates 
ranef(hct.m6, groups="species") #, probs = 0.95)
```


# hct: Plot outputs of posterior mean estimates and 95% credible intervals (full models, m1-m6)
```{r}
# Plot: Posterior mean estimates and 95% credible intervals for predictors.
# Plot these nicely and without intercepts, which throws off scale: 
# This is a graphical way to look at model fit as opposed to just dumping out model output
# Circle = point estimate (model summary, print(hct.m6))
# Thin bars = default 90% CI; adjust prob_outer=0.95 to get 95% CI 
# Thick bars = default 50% CI; adjust prob=0.50 to get anything else 
# x-axis should be scale based on value of estimates coming out of the model 

# Model 5 
color_scheme_set("blue") # nice default
hct.m5.p1 <- mcmc_plot(hct.m5, pars=c("b_elev.z", "b_elev.pos.z", "b_mass.z", "b_intravar.mass.z", "b_temp.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [hct]", title = "hct.m5: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation", "Elevation Position", "Mass", "Intravar: Mass", "Temp"))  
hct.m5.p1
ggsave(hct.m5.p1, filename = "hct.m5.p1_hct_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(hct.m5)

# Model 6
#color_scheme_set("red") # nice default
hct.m6.p1 <- mcmc_plot(hct.m6, pars=c("b_elev.z", "b_elev.pos.z", "b_intravar.mass.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [hct]", title = "hct.m6: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation", "Elevation Position", "Intravar: Mass"))   
hct.m6.p1
ggsave(hct.m6.p1, filename = "hct.m6.p1_hct_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(hct.m6)
```


# hct: Collate model summaries and WAIC scores for reduced models (m5-m6)
```{r}
# Print model summaries 
sink("hct_reduced_brms_model_summaries.txt",append = TRUE)
summary(hct.m5, waic=TRUE)
summary(hct.m6, waic=TRUE)
sink()
# print(hct.test, prob=0.95) # change CI cut-off by adjusting prob; remember Bayesian default may not be 95%

# Get model WAIC scores  
hct.m5.waic <- waic(hct.m5)
hct.m6.waic <- waic(hct.m6)
hct.waics.red <- cbind(hct.m5.waic, hct.m6.waic); hct.waics.red
write.csv(hct.waics.red, "hct_brms_models_waics.red.csv") # totally unintelligible cumbersome doc w/ all pointwise comparisons
```


# hct: CALCULATE INTRACLASS CORRELATION (ICC) EXPLAINED BY SPECIES GROUPING VARIABLE (m5-m6)
Calculated from Burkner's phylo  brms tutorial: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
Note from Burkner: Note that the phylogenetic signal is just a synonym of the intra-class correlation (ICC) used in the context phylogenetic analysis.
```{R}
# ICC = Tells you proportion of total variance in response variable that is acccounted for by species identity (i.e. clustering)

# m6 species variance 
hyp.sp.hct.m6 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.hct.m6 <- hypothesis(hct.m6, hyp.sp.hct.m6, class = NULL))
plot(hyp.sp.hct.m6)
# 11% variance explained by species 
```


# hct: MODEL COMPARISON 
```{r}
# leave one out cross-validation, lowest is "best"
# if 2*standard error > delta LOOIC, models aren't necessarily distinguishable

library(loo)
sink("hct_brms_models_all_looic.txt", append=FALSE)
LOO(hct.m1, hct.m2, hct.m3, hct.m4, hct.m5, hct.m6, reloo=FALSE) 
sink()

# compare models # Just a shorter version of the above text
# loo_compare(en.loo) # Top ranked model includes no random effects 
# 
# Calculate Bayesian R^2:
bayes_R2(hct.m1)
bayes_R2(hct.m2) # 0.118
bayes_R2(hct.m3) # 0.096
bayes_R2(hct.m4) # 0.173
bayes_R2(hct.m5) # 0.089
bayes_R2(hct.m6) # 0.159

# Model comparisons:
#        elpd_diff se_diff
# hct.m4   0.0       0.0  
# hct.m6  -0.3       2.8  
# hct.m2 -22.6       8.2  
# hct.m5 -26.9       7.9  
# hct.m3 -29.9       7.7  
# hct.m1 -70.5      13.6  

# library(modelr)
# final.hb %>%
#   data_grid(hb = seq_range(hb, n = 30)) %>%
#   add_predicted_draws(hb.m4) %>%
#   ggplot(aes(x = elev, y = hb)) +
#   stat_lineribbon(aes(y = .prediction), .width = c(.99, .95, .8, .5), color = "#08519C") +
#   geom_point(data = final.hb, size = 2) +
#   scale_fill_brewer()

# Now re-run top model with unstandardized predictors to estimate strength of relationship between Xs and y:
job::job({ # Send to a job to free up console
hct.m4.unstandardized <- 
  update(hct.m4,
        newdata = final.hct,
        formula = hct ~ 1 + elev + elev_position + mass.log + tempPC1 + precipPC1 + genotype + # use non .z names!!!!
               intravar.mass + intravar.temp + intravar.precip + (1|species),
        chains = 4, cores = 4)
save(hct.m4.unstandardized, file="hct.m4.unstandardized_Predictors_SpeciesRE.RData") # save model
})
# load("hct.m4.unstandardized_Predictors_SpeciesRE.RData")

# Look at magnitude of unstandardized coefficients 
summary(hct.m4.unstandardized)
fixef(hct.m4.unstandardized)[2] # For every 1 m increase in elev, we expect Hct will increase by 0.001422985
round(fixef(hct.m4.unstandardized)[2]*1000, 2) # For every 1000m increase in elev, Hct will increase by 1.42%. 
fixef(hct.m4.unstandardized)[3] # elev_position
# Not sure if other variables are worth reporting, as they have really obscure units
```

Quick summary of top 3 models in order of ranking: 
1) Model 4: Full model + (1|species) **significantly better than most models, but only marginally better than M6 (reduced), 13% variance explained by species 
2) Model 6: Reduced model w/ just elvation and +1 species, 11% variation explained by species 
3) Model 2: Null + (1|species), 14% of variance explained by species 

**All models fit substantially better than the intercept-only model (m1), AND, it's very clear that it's important to consider variation explained by species identity.




##### TRBC MODEL SET #######


# TRBC MODELS - Set up & run models 
See phylo brms tutorial here: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
```{r}
# See what prior choices are being made for us. 
get_prior(trbc ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + intravar.mass.z + intravar.precip.z + intravar.temp.z + (1|species), data = final.trbc)
# I see why the tutorial calls one "phlyo" and one species; it's because you can't have both 

# Overwrite those (not so) terrible choices with some slightly informed priors.
# Otherwise known as 'let the data drive the model'. 
# prior1 <- c(set_prior("student_t(7, 0, 2.5)", class = "Intercept"), # Set intercept prior 
#             set_prior("student_t(3, 0, 1)", class = "b" )) # Class b = all responses 
## Need to study Ara's rationale for setting priors and maybe model my approach that way


###

# For each response variable, run 10 sets of models 
# These first 6 models represent full models; after this, I'll assess fit and then run reduced models 
# Note: I don't think we want random effect of sex because we have many unknowns! 
# Gaussian appears to fit better than student's t distribution

# MODEL 1: NULL MODEL (INTERCEPT ONLY) 
trbc.m1 <- brm(
  formula = bf(trbc ~ 1),
  data = final.trbc,
  family = gaussian(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
#  data2 = list(A = A), # Phylogeny
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000, EBL used 10000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
  # prior = c(
  #   prior(normal(0, 10), "b"),
  #   prior(normal(3, 20, 5), "Intercept"),
  #   prior(student_t(3, 0, 5), "sd"),
  #   prior(student_t(3, 0, 5), "sigma") # sigma = standard deviation
  # )
)
save(trbc.m1, file="trbc.m1_Intercept-Only.RData") # save model
#load("trbc.m1_Intercept-Only.Rdata") 


# MODEL 2: RANDOM EFFECTS-ONLY MODEL (INTERCEPT + SPECIES RANDOM EFFECTS)
trbc.m2 <- brm(
  formula = bf(trbc ~ 1 + (1|species)),
  data = final.trbc,
  family = gaussian(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
 # data2 = list(A = A), # Phylogeny
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000, EBL used 10000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
  # prior = c(
  #   prior(normal(0, 10), "b"),
  #   prior(normal(3, 20, 5), "Intercept"),
  #   prior(student_t(3, 0, 5), "sd"),
  #   prior(student_t(3, 0, 5), "sigma") # sigma = standard deviation
  # )
)
save(trbc.m2, file="trbc.m2_RandomEffectsOnly.RData") # save model
#load("trbc.m2_RandomEffectsOnly.RData") # If loading from pre-saved file and not re-running


# MODEL 3: FULL MODEL WITH NO RANDOM EFFECTS (JUST PREDICTORS)
trbc.m3 <- brm(
  formula = bf(trbc ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + genotype +
               intravar.mass.z + intravar.temp.z + intravar.precip.z),
  data = final.trbc,
  family = gaussian(),
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000, EBL used 10000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(trbc.m3, file="trbc.m3_FullModel_PredictorsOnly.RData") # save model
# Run time: ~1 minute
load("trbc.m3_FullModel_PredictorsOnly.RData") # If loading from pre-saved file and not re-running


# MODEL 4: FULL MODEL WITH ONLY SPECIES RANDOM EFFECT
trbc.m4 <- brm(
  formula = bf(trbc ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + genotype +
               intravar.mass.z + intravar.temp.z + intravar.precip.z 
               + (1|species)),
  data = final.trbc,
  family = gaussian(), 
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000, EBL used 10000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(trbc.m4, file="trbc.m4_FullModel_SpeciesREOnly.RData") # save model
#load("trbc.m4_FullModel_SpeciesREOnly.RData") 
```


# trbc: Summarize and check fit for full models (m1-m6)
Explanation of what mcmc_plot output below means: https://cran.r-project.org/web/packages/bayesplot/vignettes/plotting-mcmc-draws.html
```{r}
# FIT AND CONVERGENCE 

# Check trace plots for convergence
# Beginning will look crappy because of burn-in, but we want output to look like a "fuzzy caterpillar", aka noise is good
# Any plateaus/flat horizontal lines are bad, suggest we're sampling the same spot in the distribution repeatedly 
mcmc_plot(trbc.m4, type = "trace") 
plot(trbc.m4, N = 2, ask = FALSE)

# y to y-rep fit plot 
# Generate new y values given the model and compare to actual y from the data. 
# You want the y rep line to be somewhat close to dark line, signifying that model fits the data
bayesplot::pp_check(trbc.m4, resp = "trbc", nsamples = 100) # pull 100 draws from model and cast back to original data 
bayesplot::pp_check(trbc.m4, type = "stat", stat = 'median', nsamples = 100)

# Is there presence of strong autocorrelation?
# If you have autocorrelation, you get a bunch of red things flagged 
# 1, 2, 3, 4, are chains = all 4 behaving more or less the same 
# you'd see a bright red bar if something is out of whack
# Pale bars = you want all heading towards zero to show they're not correlating w/ each other across the chains 
# fine to be pos and neg, jumping around to get to zero
mcmc_plot(trbc.m4, type = "acf_bar")

# plot conditional effects for full model (note: you do this separately below)
# Note: this used to be called marginal_effects, but that's now deprecated; replaced w/ conditional_effects
# nu = degrees of freedom
plot(conditional_effects(trbc.m4), points = TRUE) 

# Quick plot of estimates and 95% CIs (default is 95% CI:
mcmc_plot(trbc.m4)  # adjust prob to get 95% CI

# Changes the fixed effects (i.e. random variable) to odd's ratio 
exp(fixef(trbc.m4)[,-2])

# Print group level variable (in log odds)
# ranef is still an array, so not an exponent on it, hard to change to probability estimates 
ranef(trbc.m4, groups="species") #, probs = 0.95)


# Residual plots 
# typical residual plot but w/ addition of uncertainty associated w/ each residual given by generating draws from the dist 
# associated with each residual
final.trbc %>%
  add_residual_draws(trbc.m4) %>%
  ggplot(aes(x = .row, y = .residual)) +
  stat_pointinterval()

# qqPlots
final.trbc %>%
  add_predicted_draws(trbc.m4) %>%
  summarise(
    p_residual = mean(.prediction < trbc), # probability residual; Bayesian predictive p-value 
    z_residual = qnorm(p_residual) # quantile residuals 
  ) %>%
  ggplot(aes(sample = z_residual)) +
  geom_qq() +
  geom_abline()
# If predicted distribution is uniform, probabilities should be well calibrated
```


# trbc: Plot outputs of posterior mean estimates and 95% credible intervals (full models, m1-m6)
```{r}
# Plot: Posterior mean estimates and 95% credible intervals for predictors.
# Plot these nicely and without intercepts, which throws off scale: 
# This is a graphical way to look at model fit as opposed to just dumping out model output
# Circle = point estimate (model summary, print(trbc.m6))
# Thin bars = default 90% CI; adjust prob_outer=0.95 to get 95% CI 
# Thick bars = default 50% CI; adjust prob=0.50 to get anything else 
# x-axis should be scale based on value of estimates coming out of the model 

# Model 3 
color_scheme_set("blue") # nice default
trbc.m3.p1 <- mcmc_plot(trbc.m3, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
                                    "b_genotypeGlyMSer", "b_genotypeSerMSer",
                                    "b_intravar.mass.z", "b_intravar.temp.z", "b_intravar.precip.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [trbc]", title = "trbc.m3: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation","Elevation Position", "Mass", "Temp", "Precip", "Genotype (Gly-Ser)", "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip"))  
trbc.m3.p1
ggsave(trbc.m3.p1, filename = "trbc.m3.p1_trbc_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(trbc.m3)
# Predictors whose 95% CIs do NOT overlap zero (variables for reduced model): elev.z, temp.z

# Model 4
#color_scheme_set("red") # nice default
trbc.m4.p1 <- mcmc_plot(trbc.m4, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
                                    "b_genotypeGlyMSer", "b_genotypeSerMSer",
                                    "b_intravar.mass","b_intravar.temp", "b_intravar.precip"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [trbc]", title = "trbc.m4: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation","Elevation Position", "Mass", "Temp", "Precip", "Genotype (Gly-Ser)", "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip"))   
trbc.m4.p1
ggsave(trbc.m4.p1, filename = "trbc.m4.p1_trbc_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(trbc.m4)
# Predictors whose 95% CIs do NOT overlap zero (retain for reduced model): elev.z

####

# Summary of reducing models: 
# m5 (reduced m3) will be: elev.z, temp.z 
# m6 (reduced m4) will be: elev.z
```


# trbc: Collate model summaries and WAIC scores for full models (m1-m4)
```{r}
# Print model summaries 
sink("trbc_brms_model_summaries.txt",append = TRUE)
summary(trbc.m1, waic=TRUE)
summary(trbc.m2, waic=TRUE)
summary(trbc.m3, waic=TRUE)
summary(trbc.m4, waic=TRUE)
sink()
# print(trbc.test, prob=0.95) # change CI cut-off by adjusting prob; remember Bayesian default may not be 95%

# Get model WAIC scores  
trbc.m1.waic <- waic(trbc.m1)
trbc.m2.waic <- waic(trbc.m2)
trbc.m3.waic <- waic(trbc.m3)
trbc.m5.waic <- waic(trbc.m4)
trbc.waics <- cbind(trbc.m1.waic, trbc.m2.waic, trbc.m3.waic, trbc.m4.waic); trbc.waics
write.csv(trbc.waics, "trbc_brms_models_waics.csv") # totally unintelligible cumbersome doc w/ all pointwise comparisons 
```


# trbc: INTRACLASS CORRELATION (ICC) EXPLAINED BY SPECIES GROUPING VARIABLE  (m1-m4)
Calculated from Burkner's phylo  brms tutorial: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
Note from Burkner: Note that the phylogenetic signal is just a synonym of the intra-class correlation (ICC) used in the context phylogenetic analysis.
```{R}
# ICC = Tells you proportion of total variance in response variable that is acccounted for by species identity (i.e. clustering)

# m2 
hyp.sp.trbc.m2 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.trbc.m2 <- hypothesis(trbc.m2, hyp.sp.trbc.m2, class = NULL))
plot(hyp.sp.trbc.m2)
# 20% variance explained 

# m4 species variance 
hyp.sp.trbc.m4 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.trbc.m4 <- hypothesis(trbc.m4, hyp.sp.trbc.m4, class = NULL))
plot(hyp.sp.trbc.m4)
# 21% variance explained by species 
```


# trbc: RUN REDUCED MODELS (m5-m6)
```{r}
# MODEL 5: REDUCED MODEL WITH NO RANDOM EFFECTS (JUST PREDICTORS)
trbc.m5 <- brm(
  formula = bf(trbc ~ 1 + elev.z + temp.z),
  data = final.trbc,
  family = gaussian(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
 # data2 = list(A = A), # Phylogeny
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, # default is iter/2; shouldn't ever be larger than iter
  iter = 10000, 
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(trbc.m5, file="trbc.m5_ReducedModel_PredictorsOnly.RData") # save model
# load("trbc.m5_ReducedModel_PredictorsOnly.RData") # If loading from pre-saved file and not re-running

# MODEL 6: REDUCED MODEL WITH ONLY SPECIES RANDOM EFFECT
trbc.m6 <- brm(
  formula = bf(trbc ~ 1 + elev.z + (1|species)),
  data = final.trbc,
  family = gaussian(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
 # data2 = list(A = A), # Phylogeny
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, # default is iter/2; shouldn't ever be larger than iter
  iter = 10000, 
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(trbc.m6, file="trbc.m6_ReducedModel_SpeciesREOnly.RData") # save model
# load("trbc.m6_ReducedModel_SpeciesREOnly.RData") 
```


# trbc: Summarize and check fit for reduced models (m5-m6)
Explanation of what mcmc_plot output below means: https://cran.r-project.org/web/packages/bayesplot/vignettes/plotting-mcmc-draws.html
```{r}
# FIT AND CONVERGENCE 

# Check trace plots for convergence
# Beginning will look crappy because of burn-in, but we want output to look like a "fuzzy caterpillar", aka noise is good
# Any plateaus/flat horizontal lines are bad, suggest we're sampling the same spot in the distribution repeatedly 
mcmc_plot(trbc.m6, type = "trace") 
plot(trbc.m6, N = 2, ask = FALSE)

# y to y-rep fit plot 
# Generate new y values given the model and compare to actual y from the data. 
# You want the y rep line to be somewhat close to dark line, signifying that model fits the data
bayesplot::pp_check(trbc.m6, resp = "trbc", nsamples = 100) # pull 100 draws from model and cast back to original data 
bayesplot::pp_check(trbc.m6, type = "stat", stat = 'median', nsamples = 100)

# Is there presence of strong autocorrelation?
# If you have autocorrelation, you get a bunch of red things flagged 
# 1, 2, 3, 4, are chains = all 4 behaving more or less the same 
# you'd see a bright red bar if something is out of whack
# Pale bars = you want all heading towards zero to show they're not correlating w/ each other across the chains 
# fine to be pos and neg, jumping around to get to zero
mcmc_plot(trbc.m6, type = "acf_bar")

# plot conditional effects for full model (note: you do this separately below)
# Note: this used to be called marginal_effects, but that's now deprecated; replaced w/ conditional_effects
# nu = degrees of freedom
plot(conditional_effects(trbc.m6), points = TRUE) 

# Quick plot of estimates and 95% CIs (default is 95% CI:
mcmc_plot(trbc.m6)  # adjust prob to get 95% CI

# Changes the fixed effects (i.e. random variable) to odd's ratio 
exp(fixef(trbc.m6)[,-2])

# Print group level variable (in log odds)
# ranef is still an array, so not an exponent on it, hard to change to probability estimates 
ranef(trbc.m6, groups="species") #, probs = 0.95)
```


# trbc: Plot outputs of posterior mean estimates and 95% credible intervals (full models, m1-m6)
```{r}
# Plot: Posterior mean estimates and 95% credible intervals for predictors.
# Plot these nicely and without intercepts, which throws off scale: 
# This is a graphical way to look at model fit as opposed to just dumping out model output
# Circle = point estimate (model summary, print(trbc.m6))
# Thin bars = default 90% CI; adjust prob_outer=0.95 to get 95% CI 
# Thick bars = default 50% CI; adjust prob=0.50 to get anything else 
# x-axis should be scale based on value of estimates coming out of the model 

# Model 7 
color_scheme_set("blue") # nice default
trbc.m5.p1 <- mcmc_plot(trbc.m5, pars=c("b_elev.z", "b_temp.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [trbc]", title = "trbc.m5: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation", "Temp"))  
trbc.m5.p1
ggsave(trbc.m5.p1, filename = "trbc.m5.p1_trbc_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(trbc.m5)

# Model 9
#color_scheme_set("red") # nice default
trbc.m6.p1 <- mcmc_plot(trbc.m6, pars=c("b_elev.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [trbc]", title = "trbc.m6: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation"))   
trbc.m6.p1
ggsave(trbc.m6.p1, filename = "trbc.m6.p1_trbc_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(trbc.m6)
```


# trbc: Collate model summaries and WAIC scores for reduced models (m5-m6)
```{r}
# Print model summaries 
sink("trbc_reduced_brms_model_summaries.txt",append = TRUE)
summary(trbc.m5, waic=TRUE)
summary(trbc.m6, waic=TRUE)
sink()
# print(trbc.test, prob=0.95) # change CI cut-off by adjusting prob; remember Bayesian default may not be 95%

# Get model WAIC scores  
trbc.m5.waic <- waic(trbc.m5)
trbc.m6.waic <- waic(trbc.m6)
trbc.waics.red <- cbind(trbc.m5.waic, trbc.m6.waic); trbc.waics.red
write.csv(trbc.waics.red, "trbc_brms_models_waics.red.csv") # totally unintelligible cumbersome doc w/ all pointwise comparisons
```


# trbc: CALCULATE INTRACLASS CORRELATION (ICC) EXPLAINED BY SPECIES GROUPING VARIABLE (m5-m6)
Calculated from Burkner's phylo  brms tutorial: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
Note from Burkner: Note that the phylogenetic signal is just a synonym of the intra-class correlation (ICC) used in the context phylogenetic analysis.
```{R}
# ICC = Tells you proportion of total variance in response variable that is acccounted for by species identity (i.e. clustering)

# m6 species variance 
hyp.sp.trbc.m6 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.trbc.m6 <- hypothesis(trbc.m6, hyp.sp.trbc.m6, class = NULL))
plot(hyp.sp.trbc.m6)
# 21% variance explained by species 

prior_summary(trbc.m6)
```


# trbc: MODEL COMPARISON 
```{r}
# leave one out cross-validation, lowest is "best"
# if 2*standard error > delta LOOIC, models aren't necessarily distinguishable

library(loo)
sink("trbc_brms_models_all_looic.txt", append=FALSE)
LOO(trbc.m1, trbc.m2, trbc.m3, trbc.m4, trbc.m5, trbc.m6, reloo=FALSE) 
sink()
# According to LOO, model 8 is top model 

# Get loo model weights: 
loo.list.trbc <- list(A=trbc.m1, B=trbc.m2, C=trbc.m3, D=trbc.m4, E=trbc.m5, F=trbc.m6) # names optional (affects printing)
loo_model_weights(loo.list.trbc)

# compare models # Just a shorter version of the above text
# loo_compare(en.loo) # Top ranked model includes no random effects 

# Calculate Bayesian R^2:
bayes_R2(trbc.m1)
bayes_R2(trbc.m2) # 0.133
bayes_R2(trbc.m3) # 0.049
bayes_R2(trbc.m4) # 0.169
bayes_R2(trbc.m5) # 0.032
bayes_R2(trbc.m6) # 0.145

# Model comparisons:
#         elpd_diff se_diff
# trbc.m4   0.0       0.0  
# trbc.m6  -0.2       3.8  
# trbc.m2  -3.7       4.7  
# trbc.m5 -24.9       8.1  
# trbc.m3 -29.5       7.6  
# trbc.m1 -34.5       9.2 

# Now re-run top model with unstandardized predictors to estimate strength of relationship between Xs and y:
job::job({ # Send to a job to free up console
trbc.m4.unstandardized <- 
  update(trbc.m4,
        newdata = final.trbc,
        formula = trbc ~ 1 + elev + elev_position + mass.log + tempPC1 + precipPC1 + genotype + # use non .z names!!!!
               intravar.mass + intravar.temp + intravar.precip + (1|species),
        chains = 4, cores = 4)
save(trbc.m4.unstandardized, file="trbc.m4.unstandardized_Predictors_SpeciesRE.RData") # save model
})
# load("trbc.m4.unstandardized_Predictors_SpeciesRE.RData")

# Look at magnitude of unstandardized coefficients 
summary(trbc.m4.unstandardized)
fixef(trbc.m4.unstandardized)[2] # For every 1 m increase in elev, we expect TRBC will increase by 0.0003072614
round(fixef(trbc.m4.unstandardized)[2]*1000, 2) # For every 1000m increase in elev, TRBC will increase by 0.31 units. 
# Not sure if other variables are worth reporting, as they have really obscure units
```

TRBC, Quick summary of top 3 models in order of ranking: 
1) Model 4: Full model + (1|species) **significantly better than most models, but only marginally better than M6 (reduced); 21% variance explained by species; R^2 = 0.169
2) Model 6: Reduced model w/ just elevation and +1 species, 21% variation explained by species, R^2 = 0.145 
3) Model 2: Null + (1|species), 20% of variance explained by species 

**All models fit substantially better than the intercept-only model (m1), AND, it's very clear that it's important to consider variation explained by species identity.




##### MCV MODEL SET #######


# MCV MODELS - Set up & run models 
See phylo brms tutorial here: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
```{r}
# See what prior choices are being made for us. 
get_prior(mcv ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + intravar.mass.z + intravar.precip.z + intravar.temp.z + (1|species), data = final.mcv)
# I see why the tutorial calls one "phlyo" and one species; it's because you can't have both 

# Overwrite those (not so) terrible choices with some slightly informed priors.
# Otherwise known as 'let the data drive the model'. 
# prior1 <- c(set_prior("student_t(3, 90.4, 15.9)", class = "Intercept"), # Set intercept prior
#                set_prior("normal(0, 10)", class = "b"), # Class b = all responses; weakly informative for all predictors
#                set_prior("student(3, 0, 15.9)", class = "sigma")
#                ) 
# prior1

###

# For each response variable, run 6 sets of models 
# These first 4 models represent full models; after this, I'll assess fit and then run reduced models 
# Note: I don't think we want random effect of sex because we have many unknowns! 
# Gaussian appears to fit better than student's t distribution

# MODEL 1: NULL MODEL (INTERCEPT ONLY) 
job::job({ 
mcv.m1 <- brm(formula = bf(mcv ~ 1),
  data = final.mcv,
  family = skew_normal(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000, EBL used 10000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(mcv.m1, file="mcv.m1_Intercept-Only.RData") # save model
#load("mcv.m1_Intercept-Only.Rdata") 


# MODEL 2: RANDOM EFFECTS-ONLY MODEL (INTERCEPT + SPECIES RANDOM EFFECT)
mcv.m2 <- brm(formula = bf(mcv ~ 1 + (1|species)),
  data = final.mcv,
  family = skew_normal(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000, EBL used 10000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors
)
save(mcv.m2, file="mcv.m2_RandomEffectsOnly.RData") # save model
load("mcv.m2_RandomEffectsOnly.RData") # If loading from pre-saved file and not re-running


# MODEL 3: FULL MODEL WITH NO RANDOM EFFECTS (JUST PREDICTORS)
mcv.m3 <- brm(formula = bf(mcv ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + genotype +
               intravar.mass.z + intravar.temp.z + intravar.precip.z),
  data = final.mcv,
  family = skew_normal(), 
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000, EBL used 10000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(mcv.m3, file="mcv.m3_FullModel_PredictorsOnly.RData") # save model
load("mcv.m3_FullModel_PredictorsOnly.RData") # If loading from pre-saved file and not re-running


# MODEL 4: FULL MODEL WITH ONLY SPECIES RANDOM EFFECT
mcv.m4 <- brm(formula = bf(mcv ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + genotype +
               intravar.mass.z + intravar.temp.z + intravar.precip.z + (1|species)),
  data = final.mcv,
  family = skew_normal(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  # skew_normal fits very well w/ mcv (no log) response
  # gaussian and student w/ mcv.log fit *ok* but are a bit off 
  # gen_extreme_value just doesn't fit
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000, EBL used 10000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(mcv.m4, file="mcv.m4_FullModel_SpeciesREOnly.RData") # save model
load("mcv.m4_FullModel_SpeciesREOnly.RData") # If loading from pre-saved file and not re-running
})

# # m4 WITH QUADRATIC ELEV
# Commented out because we don't *really* see a quadratic relationship in the individual-level data, nor do we expect one.
# mcv.m4.quad <- brm(formula = bf(mcv ~ 1 + elev.z + I(elev.z^2) + elev.pos.z + mass.z + temp.z + precip.z + genotype +
#                intravar.mass.z + intravar.temp.z + intravar.precip.z + (1|species)),
#   data = final.mcv,
#   family = skew_normal(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
#   cores = 4,
#   chains = 4,
#   thin = 10,
#   warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
#   iter = 10000, # nora had 20000, EBL used 10000
#   control = list(adapt_delta = 0.99, max_treedepth = 15),
#   sample_prior = TRUE # save priors 
# )
# save(mcv.m4.quad, file="mcv.m4.quad_FullModel_SpeciesREOnly.RData") # save model
# #load("mcv.m4.quad_FullModel_SpeciesREOnly.RData") # If loading from pre-saved file and not re-running
```


# mcv: Summarize and check fit for full models (m1-m4)
Explanation of what mcmc_plot output below means: https://cran.r-project.org/web/packages/bayesplot/vignettes/plotting-mcmc-draws.html
```{r}
# FIT AND CONVERGENCE 

# Check trace plots for convergence
# Beginning will look crappy because of burn-in, but we want output to look like a "fuzzy caterpillar", aka noise is good
# Any plateaus/flat horizontal lines are bad, suggest we're sampling the same spot in the distribution repeatedly 
mcmc_plot(mcv.m4, type = "trace") 
plot(mcv.m4, N = 2, ask = FALSE)

# y to y-rep fit plot 
# Generate new y values given the model and compare to actual y from the data. 
# You want the y rep line to be somewhat close to dark line, signifying that model fits the data
bayesplot::pp_check(mcv.m4, resp = "mcv", nsamples = 100) # pull 100 draws from model and cast back to original data 
bayesplot::pp_check(mcv.m4, type = "stat", stat = 'median', nsamples = 100)

# Is there presence of strong autocorrelation?
# If you have autocorrelation, you get a bunch of red things flagged 
# 1, 2, 3, 4, are chains = all 4 behaving more or less the same 
# you'd see a bright red bar if something is out of whack
# Pale bars = you want all heading towards zero to show they're not correlating w/ each other across the chains 
# fine to be pos and neg, jumping around to get to zero
mcmc_plot(mcv.m4, type = "acf_bar")

# plot conditional effects for full model (note: you do this separately below)
# Note: this used to be called marginal_effects, but that's now deprecated; replaced w/ conditional_effects
# nu = degrees of freedom
plot(conditional_effects(mcv.m4), points = TRUE) 

# Quick plot of estimates and 95% CIs (default is 95% CI:
mcmc_plot(mcv.m4)  # adjust prob to get 95% CI

# Changes the fixed effects (i.e. random variable) to odd's ratio 
exp(fixef(mcv.m4)[,-2])

# Print group level variable (in log odds)
# ranef is still an array, so not an exponent on it, hard to change to probability estimates 
ranef(mcv.m4, groups="species") #, probs = 0.95)

# Residual plots 
# typical residual plot but w/ addition of uncertainty associated w/ each residual given by generating draws from the dist 
# associated with each residual
final.mcv %>%
  add_residual_draws(mcv.m4) %>%
  ggplot(aes(x = .row, y = .residual)) +
  stat_pointinterval()

# qqPlots
final.mcv %>%
  add_predicted_draws(mcv.m4) %>%
  summarise(
    p_residual = mean(.prediction < mcv), # probability residual; Bayesian predictive p-value 
    z_residual = qnorm(p_residual) # quantile residuals 
  ) %>%
  ggplot(aes(sample = z_residual)) +
  geom_qq() +
  geom_abline()
# If predicted distribution is uniform, probabilities should be well calibrated
```


# mcv: Plot outputs of posterior mean estimates and 95% credible intervals (full models, m1-m6)
```{r}
# Plot: Posterior mean estimates and 95% credible intervals for predictors.
# Plot these nicely and without intercepts, which throws off scale: 
# This is a graphical way to look at model fit as opposed to just dumping out model output
# Circle = point estimate (model summary, print(mcv.m6))
# Thin bars = default 90% CI; adjust prob_outer=0.95 to get 95% CI 
# Thick bars = default 50% CI; adjust prob=0.50 to get anything else 
# x-axis should be scale based on value of estimates coming out of the model 

# Model 3 
color_scheme_set("blue") # nice default
mcv.m3.p1 <- mcmc_plot(mcv.m3, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
                                    "b_genotypeGlyMSer", "b_genotypeSerMSer","b_intravar.mass.z",
                                    "b_intravar.temp.z", "b_intravar.precip.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [mcv]", title = "mcv.m3: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation","Elevation Position","Mass", "Temp", "Precip", "Genotype (Gly-Ser)", "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip"))  
mcv.m3.p1
ggsave(mcv.m3.p1, filename = "mcv.m3.p1_mcv_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(mcv.m3)
# Predictors whose 95% CIs do NOT overlap zero (for reduced model): elev.z, temp.z

# Model 4
#color_scheme_set("red") # nice default
mcv.m4.p1 <- mcmc_plot(mcv.m4, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
                                    "b_genotypeGlyMSer", "b_genotypeSerMSer",
                                    "b_intravar.mass.z","b_intravar.temp.z", "b_intravar.precip.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [mcv]", title = "mcv.m4: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation", "Elevation Position", "Mass", "Temp", "Precip", "Genotype (Gly-Ser)", "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip"))   
mcv.m4.p1
ggsave(mcv.m4.p1, filename = "mcv.m4.p1_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(mcv.m4)
# Predictors whose 95% CIs do NOT overlap zero (for reduced model): temp.z

# # Model 4 - quadratic
# #color_scheme_set("red") # nice default
# mcv.m4.p1.quad <- mcmc_plot(mcv.m4.quad, pars=c("b_elev.z", "b_Ielev.zE2", 
#                                                 "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
#                                     "b_genotypeGlyMSer", "b_genotypeSerMSer",
#                                     "b_intravar.mass.z","b_intravar.temp.z", "b_intravar.precip.z"),
#                                     prob_outer=0.95, # 95% outer CI 
#                                     prob=0.50, # 50% inner CI 
#                                     point_est="mean") + # mean point est; default is median 
# labs(x="Effect on [mcv]", title = "mcv.m4.quad: Posterior mean estimates & 95% Credible Intervals") + 
# scale_y_discrete(labels=c("Elevation", "Elev Quad", "Elevation Position", "Mass", "Temp", "Precip", "Genotype (Gly-Ser)", "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip"))   
# mcv.m4.p1.quad
# ggsave(mcv.m4.p1.quad, filename = "mcv.m4.p1.quad_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
# summary(mcv.m4.quad)
# # Predictors whose 95% CIs do NOT overlap zero (for reduced model): elev.z + temp.z

####

# Summary of reducing models: 
# m5 (reduced m3) will be: elev.z, temp.z
# m6 (reduced m4) will be: temp.z
# m6.quad (reduced m4.quad) will be: elev.z + temp.z
```


# mcv: Collate model summaries and WAIC scores for full models (m1-m4)
```{r}
# Print model summaries 
sink("mcv_brms_model_summaries.txt",append = TRUE)
summary(mcv.m1, waic=TRUE)
summary(mcv.m2, waic=TRUE)
summary(mcv.m3, waic=TRUE)
summary(mcv.m4, waic=TRUE)
#summary(mcv.m4.quad, waic=TRUE)
sink()
# print(mcv.test, prob=0.95) # change CI cut-off by adjusting prob; remember Bayesian default may not be 95%

# Get model WAIC scores  
mcv.m1.waic <- waic(mcv.m1)
mcv.m2.waic <- waic(mcv.m2)
mcv.m3.waic <- waic(mcv.m3)
mcv.m4.waic <- waic(mcv.m4)
#mcv.m4.quad.waic <- waic(mcv.m4.quad)
mcv.waics <- cbind(mcv.m1.waic, mcv.m2.waic, mcv.m3.waic, mcv.m4.waic); mcv.waics
write.csv(mcv.waics, "mcv_brms_models_waics.csv") # totally unintelligible cumbersome doc w/ all pointwise comparisons 
```


# mcv: Calculate INTRACLASS CORRELATION (ICC) EXPLAINED BY SPECIES GROUPING VARIABLE (m1-m4)
Calculated from Burkner's phylo  brms tutorial: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
Note from Burkner: Note that the phylogenetic signal is just a synonym of the intra-class correlation (ICC) used in the context phylogenetic analysis.
```{R}
  # ICC = Tells you proportion of total variance in response variable that is acccounted for by species identity (i.e. clustering)

# m2 
hyp.sp.mcv.m2 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.mcv.m2 <- hypothesis(mcv.m2, hyp.sp.mcv.m2, class = NULL))
plot(hyp.sp.mcv.m2)
# 14% variance explained 

# m4 species variance 
hyp.sp.mcv.m4 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.mcv.m4 <- hypothesis(mcv.m4, hyp.sp.mcv.m4, class = NULL))
plot(hyp.sp.mcv.m4)
# 14% variance explained by species 

# # m4.quad species variance 
# hyp.sp.mcv.m4.quad <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
# (hyp.sp.mcv.m4.quad <- hypothesis(mcv.m4.quad, hyp.sp.mcv.m4.quad, class = NULL))
# plot(hyp.sp.mcv.m4.quad)
# 14% variance explained by species 
```


# mcv: RUN REDUCED MODELS (m5-m6)
```{r}
# MODEL 5: REDUCED MODEL WITH NO RANDOM EFFECTS (JUST PREDICTORS)
mcv.m5 <- brm(
  formula = bf(mcv ~ 1 + elev.z + temp.z),
  data = final.mcv,
  family = skew_normal(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, # default is iter/2; shouldn't ever be larger than iter
  iter = 10000, 
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(mcv.m5, file="mcv.m5_ReducedModel_PredictorsOnly.RData") # save model
load("mcv.m5_ReducedModel_PredictorsOnly.RData") # If loading from pre-saved file and not re-running

# MODEL 6: REDUCED MODEL WITH ONLY SPECIES RANDOM EFFECT
mcv.m6 <- brm(
  formula = bf(mcv ~ 1 + temp.z + (1|species)),
  data = final.mcv,
  family = skew_normal(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, # default is iter/2; shouldn't ever be larger than iter
  iter = 10000, 
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(mcv.m6, file="mcv.m6_ReducedModel_SpeciesREOnly.RData") # save model
load("mcv.m6_ReducedModel_SpeciesREOnly.RData") 

# # MODEL 6.QUAD: REDUCED MODEL WITH ONLY SPECIES RANDOM EFFECT
# We don't want to incorporate quadratic models for individual-level data
# mcv.m6.quad <- brm(
#   formula = bf(mcv ~ 1 + elev.z + temp.z + (1|species)),
#   data = final.mcv,
#   family = skew_normal(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
#   cores = 4,
#   chains = 4,
#   thin = 10,
#   warmup = 5000, # default is iter/2; shouldn't ever be larger than iter
#   iter = 10000, 
#   control = list(adapt_delta = 0.99, max_treedepth = 15),
#   sample_prior = TRUE # save priors 
# )
# save(mcv.m6.quad, file="mcv.m6.quad_ReducedModel_SpeciesREOnly.RData") # save model
# # load("mcv.m6.quad_ReducedModel_SpeciesREOnly.RData") 
```


# mcv: Summarize and check fit for reduced models (m5-m6)
Explanation of what mcmc_plot output below means: https://cran.r-project.org/web/packages/bayesplot/vignettes/plotting-mcmc-draws.html
```{r}
# FIT AND CONVERGENCE 

# Check trace plots for convergence
# Beginning will look crappy because of burn-in, but we want output to look like a "fuzzy caterpillar", aka noise is good
# Any plateaus/flat horizontal lines are bad, suggest we're sampling the same spot in the distribution repeatedly 
mcmc_plot(mcv.m6, type = "trace") 
plot(mcv.m6, N = 2, ask = FALSE)

# y to y-rep fit plot 
# Generate new y values given the model and compare to actual y from the data. 
# You want the y rep line to be somewhat close to dark line, signifying that model fits the data
bayesplot::pp_check(mcv.m6, resp = "mcv", nsamples = 100) # pull 100 draws from model and cast back to original data 
bayesplot::pp_check(mcv.m6, type = "stat", stat = 'median', nsamples = 100)

# Is there presence of strong autocorrelation?
# If you have autocorrelation, you get a bunch of red things flagged 
# 1, 2, 3, 4, are chains = all 4 behaving more or less the same 
# you'd see a bright red bar if something is out of whack
# Pale bars = you want all heading towards zero to show they're not correlating w/ each other across the chains 
# fine to be pos and neg, jumping around to get to zero
mcmc_plot(mcv.m6, type = "acf_bar")

# plot conditional effects for full model (note: you do this separately below)
# Note: this used to be called marginal_effects, but that's now deprecated; replaced w/ conditional_effects
# nu = degrees of freedom
plot(conditional_effects(mcv.m4), points = TRUE) 

# Quick plot of estimates and 95% CIs (default is 95% CI:
mcmc_plot(mcv.m6)  # adjust prob to get 95% CI

# Changes the fixed effects (i.e. random variable) to odd's ratio 
exp(fixef(mcv.m6)[,-2])

# Print group level variable (in log odds)
# ranef is still an array, so not an exponent on it, hard to change to probability estimates 
ranef(mcv.m6, groups="species") #, probs = 0.95)
```


# mcv: Plot outputs of posterior mean estimates and 95% credible intervals (full models, m1-m6)
```{r}
# Plot: Posterior mean estimates and 95% credible intervals for predictors.
# Plot these nicely and without intercepts, which throws off scale: 
# This is a graphical way to look at model fit as opposed to just dumping out model output
# Circle = point estimate (model summary, print(mcv.m6))
# Thin bars = default 90% CI; adjust prob_outer=0.95 to get 95% CI 
# Thick bars = default 50% CI; adjust prob=0.50 to get anything else 
# x-axis should be scale based on value of estimates coming out of the model 

# Model 5 
color_scheme_set("blue") # nice default
mcv.m5.p1 <- mcmc_plot(mcv.m5, pars=c("b_elev.z", "b_temp.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on MCV", title = "mcv.m5: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation", "Temp"))  
mcv.m5.p1
ggsave(mcv.m5.p1, filename = "mcv.m5.p1_mcv_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(mcv.m5)

# # Model 6
# color_scheme_set("teal") # nice default
mcv.m6.p1 <- mcmc_plot(mcv.m6, pars=c("b_temp.z"),
                                    prob_outer=0.95, # 95% outer CI
                                    prob=0.50, # 50% inner CI
                                    point_est="mean") + # mean point est; default is median
labs(x="Effect on MCV", title = "mcv.m6: Posterior mean estimates & 95% Credible Intervals") +
scale_y_discrete(labels=c("Temp"))
mcv.m6.p1
ggsave(mcv.m6.p1, filename = "mcv.m8.p1_mcv_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(mcv.m6)
# 
# # Model 6.quad 
# color_scheme_set("blue") # nice default
# mcv.m6.quad.p1 <- mcmc_plot(mcv.m6.quad, pars=c("b_elev.z", "b_temp.z"),
#                                     prob_outer=0.95, # 95% outer CI 
#                                     prob=0.50, # 50% inner CI 
#                                     point_est="mean") + # mean point est; default is median 
# labs(x="Effect on MCV", title = "mcv.m6.quad: Posterior mean estimates & 95% Credible Intervals") + 
# scale_y_discrete(labels=c("Elevation", "Temp"))  
# mcv.m6.quad.p1
# ggsave(mcv.m6.quad.p1, filename = "mcv.m6.quad.p1_mcv_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
# summary(mcv.m6.quad)
```


# mcv: Collate model summaries and WAIC scores for reduced models (m5-m6)
```{r}
# Print model summaries 
sink("mcv_reduced_brms_model_summaries.txt",append = TRUE)
summary(mcv.m5, waic=TRUE)
summary(mcv.m6, waic=TRUE)
sink()
# print(mcv.test, prob=0.95) # change CI cut-off by adjusting prob; remember Bayesian default may not be 95%

# Get model WAIC scores  
mcv.m5.waic <- waic(mcv.m5)
mcv.m6.waic <- waic(mcv.m6)
mcv.waics.red <- cbind(mcv.m5.waic, mcv.m6.waic); mcv.waics.red
write.csv(mcv.waics.red, "mcv_brms_models_waics.red.csv") # totally unintelligible cumbersome doc w/ all pointwise comparisons
```


# mcv: Calculate INTRACLASS CORRELATION (ICC) EXPLAINED BY SPECIES GROUPING VARIABL (m5-m6)
Calculated from Burkner's phylo  brms tutorial: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
Note from Burkner: Note that the phylogenetic signal is just a synonym of the intra-class correlation (ICC) used in the context phylogenetic analysis.
```{R}
# ICC = Tells you proportion of total variance in response variable that is acccounted for by species identity (i.e. clustering)

# m6 
hyp.sp.mcv.m6 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.mcv.m6 <- hypothesis(mcv.m6, hyp.sp.mcv.m6, class = NULL))
plot(hyp.sp.mcv.m6)
# 13% variance explained by species

# # m6.quad
# hyp.sp.mcv.m6.quad <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
# (hyp.sp.mcv.m6.quad <- hypothesis(mcv.m6.quad, hyp.sp.mcv.m6.quad, class = NULL))
# plot(hyp.sp.mcv.m6.quad)
# 14% variance explained by species

plot(final.mcv$mass.z, final.mcv$mcv, xlab="Mass (standardized)", ylab="MCV", pch=19)
```


# MCV: MODEL COMPARISON 
```{r}
# leave one out cross-validation, lowest is "best"
# if 2*standard error > delta LOOIC, models aren't necessarily distinguishable

library(loo)
sink("mcv_brms_models_all_looic.txt", append=FALSE)
LOO(mcv.m1, mcv.m2, mcv.m3, mcv.m4, mcv.m5, mcv.m6, reloo=TRUE) 
sink()
# reloo=TRUE takes much longer to fit but deals with problematic observations by leaving them out of estimates
# you can also use something called moment_match=TRUE in loo, but to do this need save_pars=TRUE in models and that 
# wasn't working for some reason
# This takes ~20 minutes to run
# compare models # Just a shorter version of the above text
# loo_compare(en.loo) # Top ranked model includes no random effects 

# Calculate Bayesian R^2:
bayes_R2(mcv.m1)
bayes_R2(mcv.m2) # 0.093
bayes_R2(mcv.m3) # 0.028
bayes_R2(mcv.m4) # 0.110
bayes_R2(mcv.m4.quad) # 0.115
bayes_R2(mcv.m5) # 0.008
bayes_R2(mcv.m6) # 0.094

# Model comparisons:
#        elpd_diff se_diff
# mcv.m6   0.0       0.0  
# mcv.m2  -0.6       1.1  
# mcv.m4  -0.8       3.6  
# mcv.m5 -23.3       7.1  
# mcv.m1 -24.8       6.9  
# mcv.m3 -26.5       7.3  

# Now re-run top model with unstandardized predictors to estimate strength of relationship between Xs and y:
job::job({ # Send to a job to free up console
mcv.m6.unstandardized <- 
  update(mcv.m6,
        newdata = final.trbc,
        formula = trbc ~ 1 + tempPC1 + (1|species), # use non .z names!!!!
        chains = 4, cores = 4)
save(mcv.m6.unstandardized, file="mcv.m6.unstandardized_Predictors_SpeciesRE.RData") # save model
})
# load("mcv.m6.unstandardized_Predictors_SpeciesRE.RData")

# Look at magnitude of unstandardized coefficients 
summary(mcv.m6.unstandardized)
fixef(mcv.m6.unstandardized)[2] # For every 1 unit increase in temp composite, we expect MCV will decrease by -0.02283523
round(fixef(mcv.m6.unstandardized)[2]*5, 2) # For every 5-unit (degree?) increase in temp composit, MCV will decrease by -0.11 fl.  
# Not sure if other variables are worth reporting, as they have really obscure units

# *Note: These estimates are from reduced model; need to use full model if we want elev,  etc. 
```


MCV, Quick summary of top 3 models in order of ranking (this does not include quadratic model summary!): 
1) Model 6: Reduced model w/ just temp.z and +1 species; 13% variation explained by species, R^2 = 0.094 
2) Model 2: Null model + (1|species), only marginally below than M6 (reduced); 14% variance explained by species, R^2 = 0.093
3) Model 4: Full + (1|species); 14% of variance explained by species; R^2 = 0.110 

**All models w/ random effect of species fit better than without, suggesting that this is important. 



##### MCH MODEL SET #######


# MCH MODELS - Set up & run models 
See phylo brms tutorial here: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
```{r}
# See what prior choices are being made for us. 
get_prior(mch ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + intravar.mass.z + intravar.precip.z + intravar.temp.z + (1|species), data = final.mch)
# I see why the tutorial calls one "phlyo" and one species; it's because you can't have both 

# Overwrite those (not so) terrible choices with some slightly informed priors.
# Otherwise known as 'let the data drive the model'. 
# prior1 <- c(set_prior("student_t(7, 0, 2.5)", class = "Intercept"), # Set intercept prior 
#             set_prior("student_t(3, 0, 1)", class = "b" )) # Class b = all responses 
## Need to study Ara's rationale for setting priors and maybe model my approach that way


###

# MODEL 1: NULL MODEL (INTERCEPT ONLY) 
mch.m1 <- brm(
  formula = bf(mch ~ 1),
  data = final.mch,
  family = skew_normal(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000, EBL used 10000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(mch.m1, file="mch.m1_Intercept-Only.RData") # save model
#load("mch.m1_Intercept-Only.Rdata") 


# MODEL 2: RANDOM EFFECTS-ONLY MODEL (INTERCEPT + SPECIES RANDOM EFFECTS)
mch.m2 <- brm(
  formula = bf(mch ~ 1 + (1|species)),
  data = final.mch,
  family = skew_normal(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(mch.m2, file="mch.m2_RandomEffectsOnly.RData") # save model
#load("mch.m2_RandomEffectsOnly.RData") # If loading from pre-saved file and not re-running


# MODEL 3: FULL MODEL WITH NO RANDOM EFFECTS (JUST PREDICTORS)
mch.m3 <- brm(
  formula = bf(mch ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + genotype +
               intravar.mass.z + intravar.temp.z + intravar.precip.z),
  data = final.mch,
  family = skew_normal(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(mch.m3, file="mch.m3_FullModel_PredictorsOnly.RData") # save model
# Run time: ~1 minute
#load("mch.m3_FullModel_PredictorsOnly.RData") # If loading from pre-saved file and not re-running


# MODEL 4: FULL MODEL WITH ONLY SPECIES RANDOM EFFECT
mch.m4 <- brm(
  formula = bf(mch ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + genotype +
               intravar.mass.z + intravar.temp.z + intravar.precip.z + (1|species)),
  data = final.mch,
  family = skew_normal(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(mch.m4, file="mch.m4_FullModel_SpeciesREOnly.RData") # save model
# ~3 mins
#load("mch.m4_FullModel_SpeciesREOnly.RData") 

```


# mch: Summarize and check fit for full models (m1-m4)
Explanation of what mcmc_plot output below means: https://cran.r-project.org/web/packages/bayesplot/vignettes/plotting-mcmc-draws.html
```{r}
# FIT AND CONVERGENCE 

# Check trace plots for convergence
# Beginning will look crappy because of burn-in, but we want output to look like a "fuzzy caterpillar", aka noise is good
# Any plateaus/flat horizontal lines are bad, suggest we're sampling the same spot in the distribution repeatedly 
mcmc_plot(mch.m4, type = "trace") 
plot(mch.m4, N = 2, ask = FALSE)

# y to y-rep fit plot 
# Generate new y values given the model and compare to actual y from the data. 
# You want the y rep line to be somewhat close to dark line, signifying that model fits the data
bayesplot::pp_check(mch.m4, resp = "mch", nsamples = 100) # pull 100 draws from model and cast back to original data 
bayesplot::pp_check(mch.m4, type = "stat", stat = 'median', nsamples = 100)

# Is there presence of strong autocorrelation?
# If you have autocorrelation, you get a bunch of red things flagged 
# 1, 2, 3, 4, are chains = all 4 behaving more or less the same 
# you'd see a bright red bar if something is out of whack
# Pale bars = you want all heading towards zero to show they're not correlating w/ each other across the chains 
# fine to be pos and neg, jumping around to get to zero
mcmc_plot(mch.m4, type = "acf_bar")

# plot conditional effects for full model (note: you do this separately below)
# Note: this used to be called marginal_effects, but that's now deprecated; replaced w/ conditional_effects
# nu = degrees of freedom
plot(conditional_effects(mch.m4), points = TRUE) 

# Quick plot of estimates and 95% CIs (default is 95% CI:
mcmc_plot(mch.m4)  # adjust prob to get 95% CI

# Changes the fixed effects (i.e. random variable) to odd's ratio 
exp(fixef(mch.m4)[,-2])

# Print group level variable (in log odds)
# ranef is still an array, so not an exponent on it, hard to change to probability estimates 
ranef(mch.m4, groups="species") #, probs = 0.95)

# Residual plots 
# typical residual plot but w/ addition of uncertainty associated w/ each residual given by generating draws from the dist 
# associated with each residual
final.mch %>%
  add_residual_draws(mch.m4) %>%
  ggplot(aes(x = .row, y = .residual)) +
  stat_pointinterval()

# qqPlots
final.mch %>%
  add_predicted_draws(mch.m4) %>%
  summarise(
    p_residual = mean(.prediction < mch), # probability residual; Bayesian predictive p-value 
    z_residual = qnorm(p_residual) # quantile residuals 
  ) %>%
  ggplot(aes(sample = z_residual)) +
  geom_qq() +
  geom_abline()
# If predicted distribution is uniform, probabilities should be well calibrated
```


# mch: Plot outputs of posterior mean estimates and 95% credible intervals (full models, m1-m6)
```{r}
# Plot: Posterior mean estimates and 95% credible intervals for predictors.
# Plot these nicely and without intercepts, which throws off scale: 
# This is a graphical way to look at model fit as opposed to just dumping out model output
# Circle = point estimate (model summary, print(mch.m6))
# Thin bars = default 90% CI; adjust prob_outer=0.95 to get 95% CI 
# Thick bars = default 50% CI; adjust prob=0.50 to get anything else 
# x-axis should be scale based on value of estimates coming out of the model 

# Model 3 
color_scheme_set("blue") # nice default
mch.m3.p1 <- mcmc_plot(mch.m3, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
                                    "b_genotypeGlyMSer", "b_genotypeSerMSer",
                                    "b_intravar.mass","b_intravar.temp", "b_intravar.precip"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [mch]", title = "mch.m3: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation","Elevation Position", "Mass", "Temp", "Precip", "Genotype (Gly-Ser)", "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip"))  
mch.m3.p1
ggsave(mch.m3.p1, filename = "mch.m3.p1_mch_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(mch.m3)
# Predictors whose 95% CIs do NOT overlap zero (for reduced model): elev.z, temp.z

# Model 4
#color_scheme_set("red") # nice default
mch.m4.p1 <- mcmc_plot(mch.m4, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
                                    "b_genotypeGlyMSer", "b_genotypeSerMSer",
                                    "b_intravar.mass","b_intravar.temp", "b_intravar.precip"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [mch]", title = "mch.m4: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation","Elevation Position","Mass", "Temp", "Precip", "Genotype (Gly-Ser)", "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip"))   
mch.m4.p1
ggsave(mch.m4.p1, filename = "mch.m4.p1_mch_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(mch.m4)
# Predictors whose 95% CIs do NOT overlap zero (for reduced models): elev.z, temp.z 

####

# Summary of reducing models: 
# m5 (reduced m3) will be: elev.z, temp.z
# m6 (reduced m4) will be: elev.z, temp.z
```


# mch: Collate model summaries and WAIC scores for full models (m1-m6)
```{r}
# Print model summaries 
sink("mch_brms_model_summaries.txt",append = TRUE)
summary(mch.m1, waic=TRUE)
summary(mch.m2, waic=TRUE)
summary(mch.m3, waic=TRUE)
summary(mch.m4, waic=TRUE)
sink()
# print(mch.test, prob=0.95) # change CI cut-off by adjusting prob; remember Bayesian default may not be 95%

# Get model WAIC scores  
mch.m1.waic <- waic(mch.m1)
mch.m2.waic <- waic(mch.m2)
mch.m3.waic <- waic(mch.m3)
mch.m4.waic <- waic(mch.m4)
mch.waics <- cbind(mch.m1.waic, mch.m2.waic, mch.m3.waic, mch.m4.waic); mch.waics
write.csv(mch.waics, "mch_brms_models_waics.csv") # totally unintelligible cumbersome doc w/ all pointwise comparisons 
```


# mch: Calculate INTRACLASS CORRELATION (ICC) EXPLAINED BY SPECIES GROUPING VARIABLE  (m1-m4)
Calculated from Burkner's phylo  brms tutorial: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
Note from Burkner: Note that the phylogenetic signal is just a synonym of the intra-class correlation (ICC) used in the context phylogenetic analysis.
```{R}
# ICC = Tells you proportion of total variance in response variable that is acccounted for by species identity (i.e. clustering)

# m2 
hyp.sp.mch.m2 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.mch.m2 <- hypothesis(mch.m2, hyp.sp.mch.m2, class = NULL))
plot(hyp.sp.mch.m2)
# 12% variance explained 

# m4 species variance 
hyp.sp.mch.m4 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.mch.m4 <- hypothesis(mch.m4, hyp.sp.mch.m4, class = NULL))
plot(hyp.sp.mch.m4)
# 12% variance explained by species 
```


# mch: RUN REDUCED MODELS (m5-m6)
```{r}
# MODEL 5: REDUCED MODEL WITH NO RANDOM EFFECTS (JUST PREDICTORS)
mch.m5 <- brm(
  formula = bf(mch ~ 1 + elev.z + temp.z),
  data = final.mch,
  family = skew_normal(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, # default is iter/2; shouldn't ever be larger than iter
  iter = 10000, 
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(mch.m5, file="mch.m5_ReducedModel_PredictorsOnly.RData") # save model
#load("mch.m5_ReducedModel_PredictorsOnly.RData") # If loading from pre-saved file and not re-running

# MODEL 6: REDUCED MODEL WITH ONLY SPECIES RANDOM EFFECT
mch.m6 <- brm(
  formula = bf(mch ~ 1 + elev.z + temp.z + (1|species)),
  data = final.mch,
  family = skew_normal(), 
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, # default is iter/2; shouldn't ever be larger than iter
  iter = 10000,
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors
)
save(mch.m6, file="mch.m6_ReducedModel_PhyloREOnly.RData") # save model
# load("mch.m6_ReducedModel_PhyloREOnly.RData") 
```


# MCH: Summarize and check fit for reduced models (m5-m6)
Explanation of what mcmc_plot output below means: https://cran.r-project.org/web/packages/bayesplot/vignettes/plotting-mcmc-draws.html
```{r}
# FIT AND CONVERGENCE 

# Check trace plots for convergence
# Beginning will look crappy because of burn-in, but we want output to look like a "fuzzy caterpillar", aka noise is good
# Any plateaus/flat horizontal lines are bad, suggest we're sampling the same spot in the distribution repeatedly 
mcmc_plot(mch.m6, type = "trace") 
plot(mch.m6, N = 2, ask = FALSE)

# y to y-rep fit plot 
# Generate new y values given the model and compare to actual y from the data. 
# You want the y rep line to be somewhat close to dark line, signifying that model fits the data
bayesplot::pp_check(mch.m6, resp = "mch", nsamples = 100) # pull 100 draws from model and cast back to original data 
bayesplot::pp_check(mch.m6, type = "stat", stat = 'median', nsamples = 100)


# Is there presence of strong autocorrelation?
# If you have autocorrelation, you get a bunch of red things flagged 
# 1, 2, 3, 4, are chains = all 4 behaving more or less the same 
# you'd see a bright red bar if something is out of whack
# Pale bars = you want all heading towards zero to show they're not correlating w/ each other across the chains 
# fine to be pos and neg, jumping around to get to zero
mcmc_plot(mch.m6, type = "acf_bar")

# plot conditional effects for full model (note: you do this separately below)
# Note: this used to be called marginal_effects, but that's now deprecated; replaced w/ conditional_effects
# nu = degrees of freedom
plot(conditional_effects(mch.m6), points = TRUE) 

# Quick plot of estimates and 95% CIs (default is 95% CI:
mcmc_plot(mch.m6)  # adjust prob to get 95% CI

# Changes the fixed effects (i.e. random variable) to odd's ratio 
exp(fixef(mch.m6)[,-2])

# Print group level variable (in log odds)
# ranef is still an array, so not an exponent on it, hard to change to probability estimates 
ranef(mch.m6, groups="species") #, probs = 0.95)
```


# mch: Plot outputs of posterior mean estimates and 95% credible intervals (full models, m1-m6)
```{r}
# Plot: Posterior mean estimates and 95% credible intervals for predictors.
# Plot these nicely and without intercepts, which throws off scale: 
# This is a graphical way to look at model fit as opposed to just dumping out model output
# Circle = point estimate (model summary, print(mch.m6))
# Thin bars = default 90% CI; adjust prob_outer=0.95 to get 95% CI 
# Thick bars = default 50% CI; adjust prob=0.50 to get anything else 
# x-axis should be scale based on value of estimates coming out of the model 

# Model 5 
color_scheme_set("blue") # nice default
mch.m5.p1 <- mcmc_plot(mch.m5, pars=c("b_elev.z", "b_temp.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [mch]", title = "mch.m5: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation", "Temperature"))  
mch.m5.p1
ggsave(mch.m5.p1, filename = "mch.m5.p1_mch_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(mch.m5)

# # Model 6
# color_scheme_set("teal") # nice default
mch.m6.p1 <- mcmc_plot(mch.m6, pars=c("b_elev.z", "b_temp.z"),
                                    prob_outer=0.95, # 95% outer CI
                                    prob=0.50, # 50% inner CI
                                    point_est="mean") + # mean point est; default is median
labs(x="Effect on [mch]", title = "mch.m6: Posterior mean estimates & 95% Credible Intervals") +
scale_y_discrete(labels=c("Elevation", "Temperature"))
mch.m6.p1
ggsave(mch.m6.p1, filename = "mch.m6.p1_mch_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(mch.m6)
```


# mch: Collate model summaries and WAIC scores for reduced models (m5-m6)
```{r}
# Print model summaries 
sink("mch_reduced_brms_model_summaries.txt",append = TRUE)
summary(mch.m5, waic=TRUE)
summary(mch.m6, waic=TRUE)
sink()
# print(mch.test, prob=0.95) # change CI cut-off by adjusting prob; remember Bayesian default may not be 95%

# Get model WAIC scores  
mch.m5.waic <- waic(mch.m5)
mch.m6.waic <- waic(mch.m6)
mch.waics.red <- cbind(mch.m5.waic, mch.m6.waic); mch.waics.red
write.csv(mch.waics.red, "mch_brms_models_waics.red.csv") # totally unintelligible cumbersome doc w/ all pointwise comparisons 
```


# mch: Calculate INTRACLASS CORRELATION (ICC) EXPLAINED BY SPECIES GROUPING VARIABLE  (m5-m6)
Calculated from Burkner's phylo  brms tutorial: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
Note from Burkner: Note that the phylogenetic signal is just a synonym of the intra-class correlation (ICC) used in the context phylogenetic analysis.
```{R}
# ICC = Tells you proportion of total variance in response variable that is acccounted for by species identity (i.e. clustering)

# m6 
hyp.sp.mch.m6 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.mch.m6 <- hypothesis(mch.m6, hyp.sp.mch.m6, class = NULL))
plot(hyp.sp.mch.m6)
# 12% variance explained by species
```


# mch: MODEL COMPARISON 
```{r}
# leave one out cross-validation, lowest is "best"
# if 2*standard error > delta LOOIC, models aren't necessarily distinguishable

library(loo)
sink("mch_brms_models_all_looic.txt", append=FALSE)
LOO(mch.m1, mch.m2, mch.m3, mch.m4, mch.m5, mch.m6, reloo=FALSE) 
sink()

# compare models # Just a shorter version of the above text
# loo_compare(en.loo) # Top ranked model includes no random effects 

# Calculate Bayesian R^2:
bayes_R2(mch.m1)
bayes_R2(mch.m2) # 0.091
bayes_R2(mch.m3) # 0.025
bayes_R2(mch.m4) # 0.114
bayes_R2(mch.m5) # 0.005
bayes_R2(mch.m6) # 0.092

# Model comparisons:
#        elpd_diff se_diff
# mch.m6   0.0       0.0  
# mch.m2   0.0       1.5  
# mch.m4  -1.2       3.1  
# mch.m1 -19.6       6.5  
# mch.m5 -20.1       6.5  
# mch.m3 -22.8       6.7  

# Now re-run top model with unstandardized predictors to estimate strength of relationship between Xs and y:
job::job({ # Send to a job to free up console
mch.m6.unstandardized <- 
  update(mch.m6,
        newdata = final.mch,
        formula = mch ~ 1 + elev + tempPC1 + (1|species), # use non .z names!!!!
        chains = 4, cores = 4)
save(mch.m6.unstandardized, file="mch.m6.unstandardized_Predictors_SpeciesRE.RData") # save model
})
# load("mch.m6.unstandardized_Predictors_SpeciesRE.RData")

# Look at magnitude of unstandardized coefficients 
summary(mch.m6.unstandardized)
fixef(mch.m6.unstandardized)[2] # For every 1 m increase in elev, we expect MCH will decrease by -0.0004775075 pg
round(fixef(mch.m6.unstandardized)[2]*1000, 2) # For every 1000m increase in elev, MCH will decrease by -0.48 pg. 
# Not sure if other variables are worth reporting, as they have really obscure units
```


MCH, Quick summary of top 3 models in order of ranking: 
1) Model 6: Reduced model w/ just elev.pos and elev (both overlap zero in reduced model) and +1 species; 12% variation explained by species, R^2 = 0.092 
2) Model 2: TIED w/ Null model + (1|species); 12% variance explained by species, R^2 = 0.091
3) Model 4: Full + (1|species); 12% of variance explained by species; R^2 = 0.114 

**Effect of species clearly important





##### MCHC MODEL SET #######


# MCHC MODELS - Set up & run models 
See phylo brms tutorial here: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
```{r}
# See what prior choices are being made for us. 
get_prior(mchc ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + intravar.mass.z + intravar.precip.z + intravar.temp.z + (1|species), data = final.mchc)
# I see why the tutorial calls one "phlyo" and one species; it's because you can't have both 

# Overwrite those (not so) terrible choices with some slightly informed priors.
# Otherwise known as 'let the data drive the model'. 
# prior1 <- c(set_prior("student_t(7, 0, 2.5)", class = "Intercept"), # Set intercept prior 
#             set_prior("student_t(3, 0, 1)", class = "b" )) # Class b = all responses 
## Need to study Ara's rationale for setting priors and maybe model my approach that way


###

# MODEL 1: NULL MODEL (INTERCEPT ONLY) 
mchc.m1 <- brm(
  formula = bf(mchc ~ 1),
  data = final.mchc,
  family = student(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(mchc.m1, file="mchc.m1_Intercept-Only.RData") # save model
#load("mchc.m1_Intercept-Only.Rdata") 


# MODEL 2: RANDOM EFFECTS-ONLY MODEL (INTERCEPT + PHYLO & SPECIES RANDOM EFFECTS)
mchc.m2 <- brm(
  formula = bf(mchc ~ 1 + (1|species)),
  data = final.mchc,
  family = student(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(mchc.m2, file="mchc.m2_RandomEffectsOnly.RData") # save model
#load("mchc.m2_RandomEffectsOnly.RData") # If loading from pre-saved file and not re-running


# MODEL 3: FULL MODEL WITH NO RANDOM EFFECTS (JUST PREDICTORS)
mchc.m3 <- brm(
  formula = bf(mchc ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + genotype +
               intravar.mass.z + intravar.temp.z + intravar.precip.z),
  data = final.mchc,
  family = student(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(mchc.m3, file="mchc.m3_FullModel_PredictorsOnly.RData") # save model
#load("mchc.m3_FullModel_PredictorsOnly.RData") # If loading from pre-saved file and not re-running


# MODEL 4: FULL MODEL WITH ONLY SPECIES RANDOM EFFECT
mchc.m4 <- brm(
  formula = bf(mchc ~ 1 + elev.z + elev.pos.z + mass.z + temp.z + precip.z + genotype +
               intravar.mass.z + intravar.temp.z + intravar.precip.z + (1|species)),
  data = final.mchc,
  family = student(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, #Nora had 10,000; default is iter/2; shouldn't ever be larger than iter
  iter = 10000, # nora had 20000
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(mchc.m4, file="mchc.m4_FullModel_SpeciesREOnly.RData") # save model
#load("mchc.m4_FullModel_SpeciesREOnly.RData") # If loading from pre-saved file and not re-running
```


# mchc: Summarize and check fit for full models (m1-m6)
Explanation of what mcmc_plot output below means: https://cran.r-project.org/web/packages/bayesplot/vignettes/plotting-mcmc-draws.html
```{r}
# FIT AND CONVERGENCE 

# Check trace plots for convergence
# Beginning will look crappy because of burn-in, but we want output to look like a "fuzzy caterpillar", aka noise is good
# Any plateaus/flat horizontal lines are bad, suggest we're sampling the same spot in the distribution repeatedly 
mcmc_plot(mchc.m4, type = "trace") 
plot(mchc.m4, N = 2, ask = FALSE)

# y to y-rep fit plot 
# Generate new y values given the model and compare to actual y from the data. 
# You want the y rep line to be somewhat close to dark line, signifying that model fits the data
bayesplot::pp_check(mchc.m4, resp = "mchc", nsamples = 100) # pull 100 draws from model and cast back to original data 
bayesplot::pp_check(mchc.m4, type = "stat", stat = 'median', nsamples = 100)

# Is there presence of strong autocorrelation?
# If you have autocorrelation, you get a bunch of red things flagged 
# 1, 2, 3, 4, are chains = all 4 behaving more or less the same 
# you'd see a bright red bar if something is out of whack
# Pale bars = you want all heading towards zero to show they're not correlating w/ each other across the chains 
# fine to be pos and neg, jumping around to get to zero
mcmc_plot(mchc.m4, type = "acf_bar")

# plot conditional effects for full model (note: you do this separately below)
# Note: this used to be called marginal_effects, but that's now deprecated; replaced w/ conditional_effects
# nu = degrees of freedom
plot(conditional_effects(mchc.m4), points = TRUE) 

# Quick plot of estimates and 95% CIs (default is 95% CI:
mcmc_plot(mchc.m4)  # adjust prob to get 95% CI

# Changes the fixed effects (i.e. random variable) to odd's ratio 
exp(fixef(mchc.m4)[,-2])

# Print group level variable (in log odds)
# ranef is still an array, so not an exponent on it, hard to change to probability estimates 
ranef(mchc.m4, groups="species") #, probs = 0.95)

# Residual plots 
# typical residual plot but w/ addition of uncertainty associated w/ each residual given by generating draws from the dist 
# associated with each residual
final.mchc %>%
  add_residual_draws(mchc.m4) %>%
  ggplot(aes(x = .row, y = .residual)) +
  stat_pointinterval()

# qqPlots
final.mchc %>%
  add_predicted_draws(mchc.m4) %>%
  summarise(
    p_residual = mean(.prediction < mchc), # probability residual; Bayesian predictive p-value 
    z_residual = qnorm(p_residual) # quantile residuals 
  ) %>%
  ggplot(aes(sample = z_residual)) +
  geom_qq() +
  geom_abline()
# If predicted distribution is uniform, probabilities should be well calibrated
```


# mchc: Plot outputs of posterior mean estimates and 95% credible intervals (full models, m1-m6)
```{r}
# Plot: Posterior mean estimates and 95% credible intervals for predictors.
# Plot these nicely and without intercepts, which throws off scale: 
# This is a graphical way to look at model fit as opposed to just dumping out model output
# Circle = point estimate (model summary, print(mchc.m6))
# Thin bars = default 90% CI; adjust prob_outer=0.95 to get 95% CI 
# Thick bars = default 50% CI; adjust prob=0.50 to get anything else 
# x-axis should be scale based on value of estimates coming out of the model 

# Model 3 
color_scheme_set("blue") # nice default
mchc.m3.p1 <- mcmc_plot(mchc.m3, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
                                    "b_genotypeGlyMSer", "b_genotypeSerMSer",
                                    "b_intravar.mass.z","b_intravar.temp.z", "b_intravar.precip.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [mchc]", title = "mchc.m3: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation","Elevation Position", "Mass", "Temp", "Precip", "Genotype (Gly-Ser)", "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip"))  
mchc.m3.p1
ggsave(mchc.m3.p1, filename = "mchc.m3.p1_mchc_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(mchc.m3)
# Predictors whose 95% CIs do NOT overlap zero (for reduced models): mass.z, genotype, intravar.mass.z, intravar.precip.z, intravar.temp.z

# Model 4
# color_scheme_set("teal") # nice default
mchc.m4.p1 <- mcmc_plot(mchc.m4, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
                                    "b_genotypeGlyMSer", "b_genotypeSerMSer",
                                    "b_intravar.mass","b_intravar.temp", "b_intravar.precip"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [mchc]", title = "mchc.m4: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Elevation","Elevation Position", "Mass", "Temp", "Precip", "Genotype (Gly-Ser)", "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip")) 
mchc.m4.p1
ggsave(mchc.m4.p1, filename = "mchc.m4.p1_mchc_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(mchc.m4)
# Predictors whose 95% CIs do NOT overlap zero (for reduced model): intravar.mass.z, intravar.temp.z

####

# Summary of reducing models: 
# m5 (reduced m3) will be: mass.z, genotype, intravar.mass.z, intravar.precip.z, intravar.temp.z
# m6 (reduced m4) will be: intravar.mass.z, intravar.temp.z
```


# mchc: Collate model summaries and WAIC scores for full models (m1-m4)
```{r}
# Print model summaries 
sink("mchc_brms_model_summaries.txt",append = TRUE)
summary(mchc.m1, waic=TRUE)
summary(mchc.m2, waic=TRUE)
summary(mchc.m3, waic=TRUE)
summary(mchc.m4, waic=TRUE)
sink()
# print(mchc.test, prob=0.95) # change CI cut-off by adjusting prob; remember Bayesian default may not be 95%

# Get model WAIC scores  
mchc.m1.waic <- waic(mchc.m1)
mchc.m2.waic <- waic(mchc.m2)
mchc.m3.waic <- waic(mchc.m3)
mchc.m4.waic <- waic(mchc.m4)
mchc.waics <- cbind(mchc.m1.waic, mchc.m2.waic, mchc.m3.waic, mchc.m4.waic); mchc.waics
write.csv(mchc.waics, "mchc_brms_models_waics.csv") # totally unintelligible cumbersome doc w/ all pointwise comparisons 
```


# mchc: Calculate INTRACLASS CORRELATION (ICC) EXPLAINED BY SPECIES GROUPING VARIABLE (m1-m4)
Calculated from Burkner's phylo  brms tutorial: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
Note from Burkner: Note that the phylogenetic signal is just a synonym of the intra-class correlation (ICC) used in the context phylogenetic analysis.
```{R}
# ICC = Tells you proportion of total variance in response variable that is acccounted for by species identity (i.e. clustering)

# m2 
hyp.sp.mchc.m2 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.mchc.m2 <- hypothesis(mchc.m2, hyp.sp.mchc.m2, class = NULL))
plot(hyp.sp.mchc.m2)
# 14% variance explained 

# m4 species variance 
hyp.sp.mchc.m4 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.mchc.m4 <- hypothesis(mchc.m4, hyp.sp.mchc.m4, class = NULL))
plot(hyp.sp.mchc.m4)
# 18% variance explained by species 
```


# mchc: RUN REDUCED MODELS (m5-m6)
```{r}
# MODEL 5: REDUCED MODEL WITH NO RANDOM EFFECTS (JUST PREDICTORS)
mchc.m5 <- brm(
  formula = bf(mchc ~ 1 + mass.z + genotype + intravar.mass.z + intravar.precip.z + intravar.temp.z),
  data = final.mchc,
  family = student(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, # default is iter/2; shouldn't ever be larger than iter
  iter = 10000, 
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(mchc.m5, file="mchc.m5_ReducedModel_PredictorsOnly.RData") # save model
#load("mchc.m5_ReducedModel_PredictorsOnly.RData") # If loading from pre-saved file and not re-running

# MODEL 6: REDUCED MODEL WITH ONLY SPECIES RANDOM EFFECT
mchc.m6 <- brm(
  formula = bf(mchc ~ 1 + intravar.mass.z + intravar.temp.z + (1|species)),
  data = final.mchc,
  family = student(), # estimates of  mean and sd in t dist are robust to outliers relative to normal dist
  cores = 4,
  chains = 4,
  thin = 10,
  warmup = 5000, # default is iter/2; shouldn't ever be larger than iter
  iter = 10000, 
  control = list(adapt_delta = 0.99, max_treedepth = 15),
  sample_prior = TRUE # save priors 
)
save(mchc.m6, file="mchc.m6_ReducedModel_SpeciesREOnly.RData") # save model
# load("mchc.m6_ReducedModel_SpeciesREOnly.RData") 
```


# MCHC: Summarize and check fit for reduced models (m5-m6)
Explanation of what mcmc_plot output below means: https://cran.r-project.org/web/packages/bayesplot/vignettes/plotting-mcmc-draws.html
```{r}
# FIT AND CONVERGENCE 

# Check trace plots for convergence
# Beginning will look crappy because of burn-in, but we want output to look like a "fuzzy caterpillar", aka noise is good
# Any plateaus/flat horizontal lines are bad, suggest we're sampling the same spot in the distribution repeatedly 
mcmc_plot(mchc.m6, type = "trace") 
plot(mchc.m6, N = 2, ask = FALSE)

# y to y-rep fit plot 
# Generate new y values given the model and compare to actual y from the data. 
# You want the y rep line to be somewhat close to dark line, signifying that model fits the data
bayesplot::pp_check(mchc.m6, resp = "mchc", nsamples = 100) # pull 100 draws from model and cast back to original data 
bayesplot::pp_check(mchc.m6, type = "stat", stat = 'median', nsamples = 100)


# Is there presence of strong autocorrelation?
# If you have autocorrelation, you get a bunch of red things flagged 
# 1, 2, 3, 4, are chains = all 4 behaving more or less the same 
# you'd see a bright red bar if something is out of whack
# Pale bars = you want all heading towards zero to show they're not correlating w/ each other across the chains 
# fine to be pos and neg, jumping around to get to zero
mcmc_plot(mchc.m6, type = "acf_bar")

# plot conditional effects for full model (note: you do this separately below)
# Note: this used to be called marginal_effects, but that's now deprecated; replaced w/ conditional_effects
# nu = degrees of freedom
plot(conditional_effects(mchc.m6), points = TRUE) 

# Quick plot of estimates and 95% CIs (default is 95% CI:
mcmc_plot(mchc.m6)  # adjust prob to get 95% CI

# Changes the fixed effects (i.e. random variable) to odd's ratio 
exp(fixef(mchc.m6)[,-2])

# Print group level variable (in log odds)
# ranef is still an array, so not an exponent on it, hard to change to probability estimates 
ranef(mchc.m6, groups="species") #, probs = 0.95)
```


# mchc: Plot outputs of posterior mean estimates and 95% credible intervals (full models, m1-m6)
```{r}
# Plot: Posterior mean estimates and 95% credible intervals for predictors.
# Plot these nicely and without intercepts, which throws off scale: 
# This is a graphical way to look at model fit as opposed to just dumping out model output
# Circle = point estimate (model summary, print(mchc.m6))
# Thin bars = default 90% CI; adjust prob_outer=0.95 to get 95% CI 
# Thick bars = default 50% CI; adjust prob=0.50 to get anything else 
# x-axis should be scale based on value of estimates coming out of the model 

# Model 5 
color_scheme_set("blue") # nice default
mchc.m5.p1 <- mcmc_plot(mchc.m5, pars=c("b_mass.z","b_genotypeGlyMSer", "b_genotypeSerMSer",
                                    "b_intravar.mass.z","b_intravar.temp.z", "b_intravar.precip.z"),
                                    prob_outer=0.95, # 95% outer CI 
                                    prob=0.50, # 50% inner CI 
                                    point_est="mean") + # mean point est; default is median 
labs(x="Effect on [mchc]", title = "mchc.m5: Posterior mean estimates & 95% Credible Intervals") + 
scale_y_discrete(labels=c("Mass", "Genotype (Gly-Ser)", "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip"))  
mchc.m5.p1
ggsave(mchc.m5.p1, filename = "mchc.m5.p1_mchc_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(mchc.m5)

# # Model 6
# color_scheme_set("teal") # nice default
mchc.m6.p1 <- mcmc_plot(mchc.m6, pars=c("b_intravar.mass.z", "b_intravar.temp.z"),
                                    prob_outer=0.95, # 95% outer CI
                                    prob=0.50, # 50% inner CI
                                    point_est="mean") + # mean point est; default is median
labs(x="Effect on [mchc]", title = "mchc.m6: Posterior mean estimates & 95% Credible Intervals") +
scale_y_discrete(labels=c("Intra Var: Mass", "Intra Var: Temp"))
mchc.m6.p1
ggsave(mchc.m6.p1, filename = "mchc.m6.p1_mchc_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")
summary(mchc.m6)
```


# mchc: Collate model summaries and WAIC scores for reduced models (m5-m6)
```{r}
# Print model summaries 
sink("mchc_reduced_brms_model_summaries.txt",append = TRUE)
summary(mchc.m5, waic=TRUE)
summary(mchc.m6, waic=TRUE)
sink()
# print(mchc.test, prob=0.95) # change CI cut-off by adjusting prob; remember Bayesian default may not be 95%

# Get model WAIC scores  
mchc.m5.waic <- waic(mchc.m5)
mchc.m6.waic <- waic(mchc.m6)
mchc.waics.red <- cbind(mchc.m5.waic, mchc.m8.waic); mchc.waics.red
write.csv(mchc.waics.red, "mchc_brms_models_waics.red.csv") # totally unintelligible cumbersome doc w/ all pointwise comparisons
```


# mchc: Calculate INTRACLASS CORRELATION (ICC) EXPLAINED BY SPECIES GROUPING VARIABLE (m5-m6)
Calculated from Burkner's phylo  brms tutorial: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html
Note from Burkner: Note that the phylogenetic signal is just a synonym of the intra-class correlation (ICC) used in the context phylogenetic analysis.
```{R}
# ICC = Tells you proportion of total variance in response variable that is acccounted for by species identity (i.e. clustering)

# m6 species variance 
hyp.sp.mchc.m6 <- "sd_species__Intercept^2 / (sd_species__Intercept^2 + sigma^2) = 0"
(hyp.sp.mchc.m6 <- hypothesis(mchc.m6, hyp.sp.mchc.m6, class = NULL))
plot(hyp.sp.mchc.m6)
# 15% variance explained by species 
```


# mchc: MODEL COMPARISON 
```{r}
# leave one out cross-validation, lowest is "best"
# if 2*standard error > delta LOOIC, models aren't necessarily distinguishable

library(loo)
sink("mchc_brms_models_all_looic.txt", append=FALSE)
LOO(mchc.m1, mchc.m2, mchc.m3, mchc.m4, mchc.m5, mchc.m6, reloo=FALSE) 
sink()
# According to LOO, model 8 is top model 

# compare models # Just a shorter version of the above text
# loo_compare(en.loo) # Top ranked model includes no random effects 

# Calculate Bayesian R^2:
bayes_R2(mchc.m1)
bayes_R2(mchc.m2) # 0.088
bayes_R2(mchc.m3) # 0.049
bayes_R2(mchc.m4) # 0.134
bayes_R2(mchc.m5) # 0.037
bayes_R2(mchc.m6) # 0.115

# Model comparisons:
#         elpd_diff se_diff
# mchc.m6   0.0       0.0  
# mchc.m4  -0.1       2.6  
# mchc.m2 -11.5       5.0  
# mchc.m3 -29.3       7.1  
# mchc.m5 -29.9       7.1  
# mchc.m1 -39.4       8.7  

# Now re-run top model with unstandardized predictors to estimate strength of relationship between Xs and y:
job::job({ # Send to a job to free up console
mchc.m6.unstandardized <- 
  update(mchc.m6,
        newdata = final.mchc,
        formula = mchc ~ 1 + intravar.mass + intravar.temp + (1|species), # use non .z names!!!!
        chains = 4, cores = 4)
save(mchc.m6.unstandardized, file="mchc.m6.unstandardized_Predictors_SpeciesRE.RData") # save model
})
# load("mchc.m6.unstandardized_Predictors_SpeciesRE.RData")

# Look at magnitude of unstandardized coefficients 
summary(mchc.m6.unstandardized)
# fixef(mchc.m6.unstandardized)[2] # For every 1 m increase in elev, we expect Hb will increase by 0.0003885536
# round(fixef(mchc.m6.unstandardized)[2]*1000, 2) # For every 1000m increase in elev, [Hb] will increase by 0.39 g/dl. 
# Not sure if other variables are worth reporting, as they have really obscure units
```

MCHC, Quick summary of top 3 models in order of ranking: 
1) Model 6: Reduced model w/ just intravar.temp and intravar.mass and +1 species; 15% variation explained by species; R^2 = 0.115 2) Model 4: Full + (1|species); 18% of variance explained by species; R^2 = 0.134. Only *marginally* lower than Model 6. 
3) Model 2: Null model + (1|species); 14% of variance explained by species; R^2 = 0.088. 

All models with species effect ranked much higher than models w/out, suggesting species very important. 



#######

### FIGURE 4 - 6-panel blood posterior probability fig 

#Set up some figure aesthetics and load in data: 
```{r}
library(tidyverse)
library(patchwork)

# Quick load to be able to make plots
load("hb.m4_FullModel_SpeciesREOnly.RData")
load("hct.m4_FullModel_SpeciesREOnly.RData")
load("trbc.m4_FullModel_SpeciesREOnly.RData") 
load("mcv.m4_FullModel_SpeciesREOnly.RData")
load("mcv.m6_ReducedModel_SpeciesREOnly.RData")
load("mch.m4_FullModel_SpeciesREOnly.RData")
load("mch.m6_ReducedModel_PhyloREOnly.RData")
load("mchc.m4_FullModel_SpeciesREOnly.RData") 
load("mchc.m6_ReducedModel_SpeciesREOnly.RData")

# Set color scheme 
color_scheme_set("viridisD")
# color_scheme_set("viridisE") # Looks most sophisticated for fig; ViridisC looks a little clownish
# Options: blue, teal, red, brightblue, purple, gray, mix-blue-red, pink; ViridisC & E are my favorite
# See help function of color_scheme_set for full list and how to mix colors 

# Note: if you use font_family "Arial" ggsave will have trouble writing this to a pdf because it makes the plot w/ Arial 
# Narrow and pdf is slightly different; either use family "Helvetica" (or any other), or follow instructions here: 
# https://github.com/thomasp85/ggraph/issues/152
```

# Print Figure 4
```{R}
# HB - panel A
color_scheme_set("viridisD")
hb.m4.fig4a <- mcmc_plot(hb.m4, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
            "b_genotypeGlyMSer", "b_genotypeSerMSer", "b_intravar.mass.z", "b_intravar.temp.z", "b_intravar.precip.z"),
            prob_outer=0.95, # 95% outer CI 
            prob=0.50, # 50% inner CI 
            point_est="mean") + # mean point est; default is median 
            labs(x="Effect on [Hb]", title = " ") + 
            scale_y_discrete(labels=c("Elevation","Elevation Position","Mass", "Temp", "Precip", "Genotype (Gly-Ser)", 
                                      "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip")) +
            theme(plot.title = element_text(family = "Helvetica", color="black",size=12)) + # font = panel header size
            theme_bw() +  #theme with white background
            theme(plot.background=element_blank(),  # eliminates background, grid lines, and chart border
                  panel.grid.major=element_blank(),  panel.grid.minor=element_blank(), panel.border=element_blank()) +
            theme(axis.line = element_line(color = 'black')) + # draws back x and y axis lines
            theme(text = element_text(family="Helvetica",size=9)) + # y axis labels
            ggtitle("A") + # Assign panel number/header
            theme(plot.title.position = "plot", # parameter "plot" specifies that you want "title" flush with y-axis
            plot.title = element_text(face="bold"))  # This makes panel header bold 
            # This is good for labeling figure panels! Avoids having to manually toy w/ hjust and vjust
            #theme(plot.margin = unit(c(0.2,0.1,0.0,0.2), "cm")) +  # top, right, bottom, left 
hb.m4.fig4a
ggsave(hb.m4.fig4a, filename = "hb.m4.fig4a_Hb_PosteriorEstimates&CredibleIntervals_ViridisC.pdf", bg="transparent", height=7, width=9, units="in")


# HCT - Panel B
color_scheme_set("viridisD")
hct.m4.fig4b <- mcmc_plot(hct.m4, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
            "b_genotypeGlyMSer", "b_genotypeSerMSer","b_intravar.mass.z", "b_intravar.temp.z", "b_intravar.precip.z"),
            prob_outer=0.95, # 95% outer CI 
            prob=0.50, # 50% inner CI 
            point_est="mean") + # mean point est; default is median 
            labs(x="Effect on Hct", title = " ") + 
            # scale_y_discrete(labels=c("Elevation","Elevation Position", "Mass", "Temp", "Precip", "Genotype (Gly-Ser)", 
            # "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip")) +  
            scale_y_discrete(labels=c("","", "", "", "", "", "", "", "", "")) + # Replace  w/ blanks for multipanel fig
            theme(plot.title = element_text(family = "Helvetica", color="black",size=12)) + # font = panel header size
            theme_bw() +  #theme with white background
            theme(plot.background=element_blank(),  # eliminates background, grid lines, and chart border
                  panel.grid.major=element_blank(),  panel.grid.minor=element_blank(), panel.border=element_blank()) +
            theme(axis.line = element_line(color = 'black')) + # draws back x and y axis lines
            theme(text = element_text(family="Helvetica",size=9)) + # y axis labels
            ggtitle("B") + # Assign panel number/header
            theme(plot.title.position = "plot", # parameter "plot" specifies that you want "title" flush with y-axis
            plot.title = element_text(face="bold"))  # This makes panel header bold 
            # This is good for labeling figure panels! Avoids having to manually toy w/ hjust and vjust
            #theme(plot.margin = unit(c(0.2,0.1,0.0,0.2), "cm")) +  # top, right, bottom, left 
hct.m4.fig4b
ggsave(hct.m4.p1, filename = "hct.m4.fig4b_hct_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")

# TRBC - Panel C
color_scheme_set("viridisD")
trbc.m4.fig4c <- mcmc_plot(trbc.m4, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
              "b_genotypeGlyMSer", "b_genotypeSerMSer", "b_intravar.mass","b_intravar.temp", "b_intravar.precip"),
              prob_outer=0.95, # 95% outer CI 
              prob=0.50, # 50% inner CI 
              point_est="mean") + # mean point est; default is median 
              labs(x="Effect on TRBC", title = " ") + 
              # scale_y_discrete(labels=c("Elevation","Elevation Position", "Mass", "Temp", "Precip","Genotype (Gly-Ser)",
              # "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip")) +
              scale_y_discrete(labels=c("","", "", "", "", "", "", "", "", "")) + # Replace  w/ blanks for multipanel fig
              theme(plot.title = element_text(family = "Helvetica", color="black",size=12)) + # font = panel header size
              theme_bw() +  #theme with white background
              theme(plot.background=element_blank(),  # eliminates background, grid lines, and chart border
                    panel.grid.major=element_blank(),  panel.grid.minor=element_blank(), panel.border=element_blank()) +
              theme(axis.line = element_line(color = 'black')) + # draws back x and y axis lines
              theme(text = element_text(family="Helvetica",size=9)) + # y axis labels
              ggtitle("C") + # Assign panel number/header
              theme(plot.title.position = "plot", # parameter "plot" specifies that you want "title" flush with y-axis
              plot.title = element_text(face="bold"))  # This makes panel header bold 
              # This is good for labeling figure panels! Avoids having to manually toy w/ hjust and vjust
              #theme(plot.margin = unit(c(0.2,0.1,0.0,0.2), "cm")) +  # top, right, bottom, left 
trbc.m4.fig4c
ggsave(trbc.m4.fig4c, filename = "trbc.m4.fig4c_trbc_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")


# MCV - panel D
color_scheme_set("viridisD")
mcv.m4.fig4d <- mcmc_plot(mcv.m4, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
             "b_genotypeGlyMSer", "b_genotypeSerMSer", "b_intravar.mass.z","b_intravar.temp.z", "b_intravar.precip.z"),
             prob_outer=0.95, # 95% outer CI 
             prob=0.50, # 50% inner CI 
             point_est="mean") + # mean point est; default is median 
             labs(x="Effect on MCV", title = " ") + 
             scale_y_discrete(labels=c("Elevation","Elevation Position", "Mass", "Temp", "Precip", "Genotype (Gly-Ser)",
                                        "Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp","Intra Var: Precip")) +
             theme(plot.title = element_text(family = "Helvetica", color="black",size=12)) + # font = panel header size
            theme_bw() +  #theme with white background
            theme(plot.background=element_blank(),  # eliminates background, grid lines, and chart border
                  panel.grid.major=element_blank(),  panel.grid.minor=element_blank(), panel.border=element_blank()) +
            theme(axis.line = element_line(color = 'black')) + # draws back x and y axis lines
             theme(text = element_text(family="Helvetica",size=9)) + # y axis labels 
             ggtitle("D") + # Assign panel number/header
             theme(plot.title.position = "plot", # parameter "plot" specifies that you want "title" flush with y-axis
             plot.title = element_text(face="bold"))  # This makes panel header bold 
             # This is good for labeling figure panels! Avoids having to manually toy w/ hjust and vjust
             #theme(plot.margin = unit(c(0.2,0.1,0.0,0.2), "cm")) +  # top, right, bottom, left 
mcv.m4.fig4d + inset_element(mcv.m6.fig4d.inset, 0.6, 0.6, 1, 1)
ggsave(mcv.m4.fig4d, filename = "mcv.m4.fig4d_mcv_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")

# MCV Inset plot (Final model, M6)
color_scheme_set("brightblue")
mcv.m6.fig4d.inset <- mcmc_plot(mcv.m6, pars=c("b_temp.z"),
                   prob_outer=0.95, # 95% outer CI
                   prob=0.50, # 50% inner CI
                   point_est="mean") + # mean point est; default is median
                   labs(x="Effect on MCV", title = " ") +
                   scale_y_discrete(labels=c("Temp")) + 
                   theme_bw() +  #theme with white background
                   theme(plot.background=element_blank(),  # eliminates background, grid lines, and chart border
                      panel.grid.major=element_blank(),  panel.grid.minor=element_blank(), panel.border=element_blank()) +
                   theme(axis.line = element_line(color = 'black')) + # draws back x and y axis lines
                   theme(plot.title = element_text(family = "Helvetica", color="black",size=8)) + # panel header size
                   theme(text = element_text(family="Helvetica", size=6)) + # y axis labels; must go AFTER AXIS CODE
                   # ggtitle("C") + # Assign panel number/header
                   theme(plot.title.position = "plot", # "plot" specifies that you want "title" flush with y-axis
                   plot.title = element_text(face="bold"))  # This makes panel header bold 
                   # This is good for labeling figure panels! Avoids having to manually toy w/ hjust and vjust
                   #theme(plot.margin = unit(c(0.2,0.1,0.0,0.2), "cm")) +  # top, right, bottom, left 
mcv.m6.fig4d.inset
ggsave(mcv.m6.fig4d.inset, filename = "mcv.m6.fig4d.inset_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")

# MCV PANEL D WITH INSET 
mcv.m4.fig4d.withinset <- mcv.m4.fig4d + inset_element(mcv.m6.fig4d.inset, 
                                                       right = 1.03, bottom = 0.7, left = 0.60, top = 1.1)
# RIGHT IS LEFT AND LEFT IS RIGHT; THIS IS VERY CONFUSING
mcv.m4.fig4d.withinset


# MCH - panel E
color_scheme_set("viridisD")
mch.m4.fig4e <- mcmc_plot(mch.m4, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
             "b_genotypeGlyMSer", "b_genotypeSerMSer", "b_intravar.mass","b_intravar.temp", "b_intravar.precip"),
             prob_outer=0.95, # 95% outer CI 
             prob=0.50, # 50% inner CI 
             point_est="mean") + # mean point est; default is median 
             labs(x="Effect on MCH", title = " ") + 
              # scale_y_discrete(labels=c("Elevation","Elevation Position","Mass", "Temp", "Precip", "Genotype (Gly-Ser)",
              #"Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip")) +
             scale_y_discrete(labels=c("","", "", "", "", "", "", "", "", "")) + # Replace  w/ blanks for multipanel fig
             theme(plot.title = element_text(family = "Helvetica", color="black",size=12)) + # font = panel header size
             theme_bw() +  #theme with white background
             theme(plot.background=element_blank(),  # eliminates background, grid lines, and chart border
                  panel.grid.major=element_blank(),  panel.grid.minor=element_blank(), panel.border=element_blank()) +
             theme(axis.line = element_line(color = 'black')) + # draws back x and y axis lines
             theme(text = element_text(family="Helvetica",size=9)) + # y axis labels 
             ggtitle("E") + # Assign panel number/header
             theme(plot.title.position = "plot", # parameter "plot" specifies that you want "title" flush with y-axis
             plot.title = element_text(face="bold"))  # This makes panel header bold 
             # This is good for labeling figure panels! Avoids having to manually toy w/ hjust and vjust
             #theme(plot.margin = unit(c(0.2,0.1,0.0,0.2), "cm")) +  # top, right, bottom, left
mch.m4.fig4e
ggsave(mch.m4.fig4e, filename = "mch.m4.fig4e_mch_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")

# MCH INSET PLOT (final model M6)
color_scheme_set("brightblue")
mch.m6.fig4e.inset <- mcmc_plot(mch.m6, pars=c("b_elev.z", "b_temp.z"),
                   prob_outer=0.95, # 95% outer CI
                   prob=0.50, # 50% inner CI
                   point_est="mean") + # mean point est; default is median
                   labs(x="Effect on MCH", title = " ") +
                   scale_y_discrete(labels=c("Elev", "Temp")) +
                   theme_bw() +  #theme with white background
                   theme(plot.background=element_blank(),  # eliminates background, grid lines, and chart border
                      panel.grid.major=element_blank(),  panel.grid.minor=element_blank(), panel.border=element_blank()) +
                   theme(axis.line = element_line(color = 'black')) + # draws back x and y axis lines
                   theme(plot.title = element_text(family = "Helvetica", color="black",size=8)) + # font=panel header size
                   theme(text = element_text(family="Helvetica",size=6)) + # y axis labels; MUST GO AFTER AXIS TEXT
                   # ggtitle("C") + # Assign panel number/header
                   theme(plot.title.position = "plot", # "plot" specifies that you want "title" flush with y-axis
                   plot.title = element_text(face="bold"))  # This makes panel header bold 
                   # This is good for labeling figure panels! Avoids having to manually toy w/ hjust and vjust
                   #theme(plot.margin = unit(c(0.2,0.1,0.0,0.2), "cm")) +  # top, right, bottom, left 
mch.m6.fig4e.inset 
ggsave(mch.m6.fig4e.inset , filename = "mch.m6.fig4e.inset _mch_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")

# MCH PANEL E WITH INSET 
mch.m4.fig4e.withinset <- mch.m4.fig4e + inset_element(mch.m6.fig4e.inset, 
                                                       right = 1.03, bottom = 0.7, left = 0.60, top = 1.1)
# RIGHT IS LEFT AND LEFT IS RIGHT; THIS IS VERY CONFUSING
mch.m4.fig4e.withinset


# MCHC - panel F
color_scheme_set("viridisD")
mchc.m4.fig4f <- mcmc_plot(mchc.m4, pars=c("b_elev.z", "b_elev.pos.z","b_mass.z","b_temp.z","b_precip.z",
              "b_genotypeGlyMSer", "b_genotypeSerMSer", "b_intravar.mass","b_intravar.temp", "b_intravar.precip"),
              prob_outer=0.95, # 95% outer CI 
              prob=0.50, # 50% inner CI 
              point_est="mean") + # mean point est; default is median 
              labs(x="Effect on MCHC", title = "") + 
              # scale_y_discrete(labels=c("Elevation","Elevation Position", "Mass", "Temp", "Precip","Genotype (Gly-Ser)",
              #"Genotype (Ser-Ser)", "Intra Var: Mass", "Intra Var: Temp", "Intra Var: Precip")) +
              scale_y_discrete(labels=c("","", "", "", "", "", "", "", "", "")) + # Replace  w/ blanks for multipanel fig
              theme(plot.title = element_text(family = "Helvetica", color="black",size=12)) + # font = panel header size
              theme_bw() +  #theme with white background
              theme(plot.background=element_blank(),  # eliminates background, grid lines, and chart border
                    panel.grid.major=element_blank(),  panel.grid.minor=element_blank(), panel.border=element_blank()) +
              theme(axis.line = element_line(color = 'black')) + # draws back x and y axis lines
              theme(text = element_text(family="Helvetica",size=9)) + # y axis labels
              ggtitle("F") + # Assign panel number/header
              theme(plot.title.position = "plot", # parameter "plot" specifies that you want "title" flush with y-axis
              plot.title = element_text(face="bold"))  # This makes panel header bold 
              # This is good for labeling figure panels! Avoids having to manually toy w/ hjust and vjust
              #theme(plot.margin = unit(c(0.2,0.1,0.0,0.2), "cm")) +  # top, right, bottom, left
mchc.m4.fig4f
ggsave(mchc.m4.fig4f, filename = "mchc.m4.fig4f_mchc_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")

# MCHC inset element 
color_scheme_set("brightblue")
mchc.m6.fig4f.inset <- mcmc_plot(mchc.m6, pars=c("b_intravar.mass.z", "b_intravar.temp.z"),
                    prob_outer=0.95, # 95% outer CI
                    prob=0.50, # 50% inner CI
                    point_est="mean") + # mean point est; default is median
                    labs(x="Effect on MCHC", title = "") +
                    scale_y_discrete(labels=c("Intra Var: \n Mass", "Intra Var: \n Temp")) + 
                    theme_bw() +  #theme with white background
                    theme(plot.background=element_blank(),  # eliminates background, grid lines, and chart border
                          panel.grid.major=element_blank(),  panel.grid.minor=element_blank(), 
                          panel.border=element_blank()) +
                    theme(axis.line = element_line(color = 'black')) + # draws back x and y axis lines
                    theme(plot.title = element_text(family = "Helvetica", color="black",size=8)) + #font=panel header size
                    theme(text = element_text(family="Helvetica",size=6)) + # y axis labels; MUST GO AFTER AXIS TEXT
                    # ggtitle("C") + # Assign panel number/header
                    theme(plot.title.position = "plot", # "plot" specifies that you want "title" flush with y-axis
                    plot.title = element_text(face="bold"))  # This makes panel header bold 
                    # This is good for labeling figure panels! Avoids having to manually toy w/ hjust and vjust
                    #theme(plot.margin = unit(c(0.2,0.1,0.0,0.2), "cm")) +  # top, right, bottom, left 
mchc.m6.fig4f.inset
ggsave(mchc.m6.fig4f.inset, filename = "mchc.m6.fig4f.inset_PosteriorEstimates&CredibleIntervals.pdf", bg="transparent", height=7, width=9, units="in")

# MCHC PANEL E WITH INSET 
mchc.m4.fig4f.withinset <- mchc.m4.fig4f + inset_element(mchc.m6.fig4f.inset, 
                                                       right = 1.03, bottom = 0.7, left = 0.60, top = 1.1)
# RIGHT IS LEFT AND LEFT IS RIGHT; THIS IS VERY CONFUSING
mchc.m4.fig4f.withinset



#### FINAL PLOT #####

library(patchwork)
# Alternative layout option = BETTER, USE THIS ONE: 
Fig4_PosteriorProbs_6panel <- (hb.m4.fig4a + hct.m4.fig4b + trbc.m4.fig4c + 
                              mcv.m4.fig4d.withinset + mch.m4.fig4e.withinset + mchc.m4.fig4f.withinset + 
                              plot_layout(guides = "collect"))
plot(Fig4_PosteriorProbs_6panel)
ggsave(Fig4_PosteriorProbs_6panel, filename = "Fig4_PosteriorProbs_6panel_05-26-21.pdf", bg="transparent", height=7, width=11, units="in")
# Why I like this format: primary blood indices align clearly in Panels A-C; secondary indices on bottom in D-F
# I originally had this set to height=7 and width=11 but somehow between March and May 2021, aesthetics got wonky

# Model summaries: 
# summary(hb.m4) # Predictors whose 95% CIs do NOT overlap zero (what reduced model will be): elev.z
# summary(hct.m4) # Predictors whose 95% CIs do NOT overlap zero (that will be in reduced model): elev.z + intravar.mass.z
# summary(trbc.m4) # Predictors whose 95% CIs do NOT overlap zero (retain for reduced model): elev.z
# summary(mcv.m4) # Predictors whose 95% CIs do NOT overlap zero (for reduced model): temp.z
# summary(mch.m4)
# summary(mchc.m4)
```


#####


---


Where I left off on Thurs 10/07/20: 
- See notes from results doc I type for Chris and Ethan - remove phylo signal as grouping variable? What do they say about mass and latitude? 
- work on improving MCV and MCH model fits by adjusting priors. Try changing distribution to student's t to see if this is any better. 
- Look at individual distributions of predictors: I bet things are wonky with mass, latitude, and *maybe* intraspecific variation because of Patagona (for mass) sampling (for lat), etc, etc. See if you can adjust priors for each of these variables to take this into account. 
- What does significance of predictors mean? 
- Figure out how to plot the data to produce nice model output plots. See if Hertel et al. 2020 Movement Ecology paper about elephants puts their code anywhere. 


I know all these links are down there somewhere, but last brms tabs I had open were: 
R-squared for Bayesian models: http://www.stat.columbia.edu/~gelman/research/unpublished/bayes_R2.pdf
Phylo multilevel models w/ brms: https://cran.r-project.org/web/packages/brms/vignettes/brms_phylogenetics.html#a-phylogenetic-model-with-repeated-measurements
brms tutorial: https://www.rensvandeschoot.com/tutorials/brms-started/
Visualizing Bayesian workflow in R: https://www.monicaalexander.com/posts/2020-28-02-bayes_viz/
Intraclass correlation coefficient in mixed models: https://www.theanalysisfactor.com/the-intraclass-correlation-coefficient-in-mixed-models/#:~:text=The%20ratio%20of%20the%20between,observations%20within%20the%20same%20cluster.

Easy Bayes - on model averaging: https://m-clark.github.io/easy-bayes/model-averaging.html
Posterior and predictive checks: https://mc-stan.org/bayesplot/reference/bayesplot::pp_check.html

Comprehensive model check (tho doesn't work w/ brms?): https://easystats.github.io/performance/








#######

###### TUTORIALS AND OTHER OPTIONS BELOW THIS LINE #######

Important info on intraclass correlation coefficient (i.e. variance explained): https://www.theanalysisfactor.com/the-intraclass-correlation-coefficient-in-mixed-models/#:~:text=The%20ratio%20of%20the%20between,observations%20within%20the%20same%20cluster.

Info for calculating intraclass correlation (ICC), aka % variation explained, by grouping variables like 'species': https://www.rensvandeschoot.com/tutorials/brms-started/


Info on choosing priors: https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations


Really good recs on this site: https://m-clark.github.io/easy-bayes/posterior-predictive-checks.html


When you do not specify priors for the regression coefficients, BRMS will pick priors that are non or very weakly informative, so that their influence on the results will be negligible.

To test whether all regression coefficients are different from zero, we can look at the Credible Intervals that are listed in the summary output or we can visually represent them in density plots. If we do so, we clearly see that zero is not included in any of the density plots, meaning that we can be reasonably certain the regression coefficients are different from zero.

We can see that both the level 1 and level 2 variables are different from zero (0 is not included in any of the CCIs)

This might be helpful but may not have much brms info? 
https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/sampling-the-imaginary.html#summary-lets-practice-in-brms


ETHAN LINCK'S INSTRUCTIONS FOR GETTING DELTA LOOIC: 
there is a delta LOOIC output—type “loo_obj$” and press tab to see the options 


If this is still relevant after individual subsets: dealing w/ missing data in brms: https://cran.r-project.org/web/packages/brms/vignettes/brms_missings.html

Tips for aggregating and analyzing data w/ dplyr: http://kbroman.org/datacarpentry_R_2016-06-01/03-dplyr.html

Bayesian credible intervals: https://easystats.github.io/bayestestR/articles/credible_interval.html



# Hb model test: tidy bayes option: 
```{r}
# Write out estimates from all chains and iterations in model  
# hb.m3 %>%
#   gather_draws(b_Intercept, b_elev.z, b_elev.position.z, b_lat.z, b_mass.z, b_temp.z, b_precip.z, b_genotypeGlyMSer, b_genotypeSerMSer, b_intravar.elev, b_intravar.elev.pos, b_intravar.lat, b_intravar.mass, b_intravar.tempPC1, b_intravar.precipPC1) %>%
#   write.csv("hb.m3.draws.csv")
# 
# # read data
# hb.m3.draws <- read.csv("hb.m3.draws.csv", stringsAsFactors = TRUE)
# hb.m3.draws <- credibility_coder(hb.m3.draws)
# 
# hb.m3.tidy <- (ggplot(data=hb.m3.draws, aes(y = .variable, x = .value)) +
#   stat_halfeye(aes(fill="#859900")) + # EBL had this as "fill=credible", but I'm not sure what "credible" is 
#   geom_vline(xintercept = 0, linetype = "dashed") +
#   scale_fill_manual(values = c("gray80","darkred","darksalmon"),
#                     name="Credible Interval",
#                        breaks=c(0, 1, 2),
#                        labels=c("NA", "95%", "89%")) +  
#   theme_bw() +
#   geom_vline(xintercept = 0, linetype="dashed") +
#   xlab(expression(Beta)) +
#   ylab(element_blank()) + 
#   scale_y_discrete(breaks=c("b_elev",
#                             "b_elev_position",
#                             "b_lat.z",
#                             "b_mass.z",
#                             "b_temp.z",
#                             "b_precip.z",
#                             "b_genotypeGlyMSer",
#                             "b_genotypeSerMSer",
#                             "b_intravar.elev",
#                             "b_intravar.elev.pos",
#                             "b_intravar.lat",
#                             "b_intravar.mass",
#                             "b_intravar.tempPC1",
#                             "b_intravar.precipPC1"),
#                    labels=c("Elevation","Elevation Position", "Latitude", "Mass", "Temp PC1", "Precip PC1", "b13b83: Gly-Ser", "b13b83: Ser-Ser", "Within sp: Elev", "Within sp: Elev pos", "Within sp: Lat", "Within sp: Mass", "Within sp: tempPC1", "Within sp: precipPC1")) +
#   ggtitle("Hb.m3"))
# print(hb.m3.tidy)
# 
# # Note: this is essentially the same as my mcmc_plot method, but using TidyBayes
# # Produces nice geom-halfeye plots like EBL is using for blood data to show CIs, colored by credible interval
# # Mine look wonky because presumably I'm manually calling fewer things than are pulled when I make the draws .csv

```


Tidybayes tutorial for plotting...just playing around with some stuff: 
Good info: http://mjskay.github.io/tidybayes/articles/tidy-brms.html
```{r}
get_variables(hb.m6) # get variables that appear in the model 

library(magrittr)
library(dplyr)
library(purrr)
library(forcats)
library(tidyr)
library(modelr)
library(ggdist)
library(tidybayes)
library(ggplot2)
library(cowplot)
library(rstan)
library(brms)
library(ggrepel)
library(RColorBrewer)
library(gganimate)

m %>% spread_draws(r_species[species,]) %>%
  head(10)


test %>%
  group_by(genotype) %>%
  data_grid(hp = seq_range(hp, n = 51)) %>%
  add_fitted_draws(hb.m6) %>%
  ggplot(aes(x = genotype, y = hb, color = ordered(genotype))) +
  stat_lineribbon(aes(y = .value)) +
  geom_point(data = final.hb) +
  scale_fill_brewer(palette = "Greys") +
  scale_color_brewer(palette = "Set2")

```


# Print environment for reproducibility
```{r}
sessionInfo() # List of packages and versions in use 
```

###########

## END 





